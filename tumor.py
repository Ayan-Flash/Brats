import os
import sys
import json
import datetime
import argparse
import numpy as np
import nibabel as nib
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from scipy.ndimage import rotate, center_of_mass, label  # For data augmentation and tumor analysis
from skimage import exposure, measure, morphology  # For image enhancement and tumor pattern analysis
from PIL import Image

# Disable MKL to avoid compatibility issues
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['TF_DISABLE_MKL'] = '1'

import tensorflow as tf
import math
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate, Activation
from tensorflow.keras.layers import BatchNormalization, Conv2DTranspose, Multiply, Lambda
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, Callback
import cv2
from tqdm import tqdm
import gc  # For garbage collection
import psutil  # For memory monitoring (optional)

# Custom F1 Score metric for training monitoring
class F1Score(tf.keras.metrics.Metric):
    """Custom F1 Score metric for binary segmentation"""
    
    def __init__(self, name='f1_score', **kwargs):
        super(F1Score, self).__init__(name=name, **kwargs)
        self.precision_metric = tf.keras.metrics.Precision()
        self.recall_metric = tf.keras.metrics.Recall()
    
    def update_state(self, y_true, y_pred, sample_weight=None):
        self.precision_metric.update_state(y_true, y_pred, sample_weight)
        self.recall_metric.update_state(y_true, y_pred, sample_weight)
    
    def result(self):
        precision = self.precision_metric.result()
        recall = self.recall_metric.result()
        
        # F1 = 2 * (precision * recall) / (precision + recall)
        f1 = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())
        return f1
    
    def reset_state(self):
        self.precision_metric.reset_state()
        self.recall_metric.reset_state()

# Alternative F1 Score using TensorFlow operations (more efficient)
def f1_score_metric(y_true, y_pred):
    """F1 Score metric function for compilation"""
    y_pred = tf.cast(y_pred > 0.5, tf.float32)
    y_true = tf.cast(y_true, tf.float32)
    
    # Calculate True Positive, False Positive, False Negative
    tp = tf.reduce_sum(y_true * y_pred)
    fp = tf.reduce_sum((1 - y_true) * y_pred)
    fn = tf.reduce_sum(y_true * (1 - y_pred))
    
    # Calculate precision and recall
    precision = tp / (tp + fp + tf.keras.backend.epsilon())
    recall = tp / (tp + fn + tf.keras.backend.epsilon())
    
    # Calculate F1 score
    f1 = 2 * precision * recall / (precision + recall + tf.keras.backend.epsilon())
    
    return f1
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, Alignment
from openpyxl.utils.dataframe import dataframe_to_rows

# Paths and auto-detection
ROOT_DIR = os.path.dirname(os.path.abspath(__file__))

# User dataset override: set this to your training/validation folder.
# If this path exists it will be used for both training and validation automatically.
USER_DATASET_DIR = r"D:\Small Tranning\Small dataset 10 train + 3 valid"

def get_memory_usage():
    """Get current memory usage in MB"""
    try:
        process = psutil.Process(os.getpid())
        memory_mb = process.memory_info().rss / 1024 / 1024
        return memory_mb
    except ImportError:
        return "Unknown (psutil not available)"
    except Exception:
        return "Unknown"

def find_data_path():
    """Auto-detect BraTS data directory within the repo."""
    # First check for user-specified dataset directory
    if USER_DATASET_DIR and os.path.isdir(USER_DATASET_DIR):
        print(f"Using user-specified dataset path: {USER_DATASET_DIR}")
        return USER_DATASET_DIR
    
    # Fallback to original candidates
    candidates = [
        os.path.join(ROOT_DIR, "BraTS2020_TrainingData", "MICCAI_BraTS2020_TrainingData"),
        os.path.join(ROOT_DIR, "archive", "BraTS2020_TrainingData", "MICCAI_BraTS2020_TrainingData"),
        os.path.join(ROOT_DIR, "archive", "BraTS2020_TrainingData"),
    ]
    for path in candidates:
        if os.path.isdir(path):
            print(f"Using training data path: {path}")
            return path
    print("Warning: Could not find BraTS training data directory. Checked: " + " | ".join(candidates))
    return None

def find_validation_path():
    """Auto-detect BraTS validation data directory."""
    # Use the same user dataset directory for validation if specified
    if USER_DATASET_DIR and os.path.isdir(USER_DATASET_DIR):
        print(f"Using user-specified dataset path for validation: {USER_DATASET_DIR}")
        return USER_DATASET_DIR
    
    # Fallback to original candidates
    candidates = [
        os.path.join(ROOT_DIR, "BraTS2020_ValidationData", "MICCAI_BraTS2020_ValidationData"),
        os.path.join(ROOT_DIR, "BraTS2020_ValidationData"),
        os.path.join(ROOT_DIR, "archive", "BraTS2020_ValidationData", "MICCAI_BraTS2020_ValidationData"),
        os.path.join(ROOT_DIR, "archive", "BraTS2020_ValidationData"),
    ]
    for path in candidates:
        if os.path.isdir(path):
            print(f"Using validation data path: {path}")
            return path
    print("Warning: Validation data path not found. Will use training data for validation.")
    return None

DATA_PATH = find_data_path()
VALIDATION_PATH = find_validation_path()
RESULTS_PATH = os.path.join(ROOT_DIR, "results")
SEGMENTED_IMAGES_PATH = os.path.join(RESULTS_PATH, "segmented_images")
METRICS_PATH = os.path.join(RESULTS_PATH, "metrics")

# Custom callback to save training metrics to Excel
class ExcelMetricsLogger(Callback):
    """Custom callback to save per-epoch training metrics to Excel file"""
    
    def __init__(self, filepath, model_name):
        super().__init__()
        self.filepath = filepath
        self.model_name = model_name
        self.metrics_data = []
        
    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        print(f"Excel Logger: Saving epoch {epoch + 1} metrics for {self.model_name}")
        print(f"Excel Logger: Available metrics: {list(logs.keys())}")
        
        # Collect metrics for this epoch - use actual metric names from logs
        epoch_data = {
            'Epoch': epoch + 1,
        }
        
        # Add all available metrics from logs
        for key, value in logs.items():
            epoch_data[key] = value
        
        self.metrics_data.append(epoch_data)
        print(f"Excel Logger: Added data for epoch {epoch + 1}, total epochs: {len(self.metrics_data)}")
        
        # Save to Excel after each epoch
        self.save_to_excel()
    
    def save_to_excel(self):
        """Save current metrics data to Excel file"""
        try:
            print(f"Excel Logger: Attempting to save to {self.filepath}")
            
            # Create DataFrame
            df = pd.DataFrame(self.metrics_data)
            
            # Create Excel workbook
            wb = Workbook()
            ws = wb.active
            ws.title = f"{self.model_name} Metrics"
            
            # Add title
            title_row = 1
            ws.merge_cells(f'A{title_row}:{chr(64 + len(df.columns))}{title_row}')
            title_cell = ws[f'A{title_row}']
            title_cell.value = f"{self.model_name} - Per-Epoch Training Metrics"
            title_cell.font = Font(size=14, bold=True)
            title_cell.alignment = Alignment(horizontal='center')
            title_cell.fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')
            
            # Add headers
            headers = list(df.columns)
            header_row = 2
            for col, header in enumerate(headers, 1):
                cell = ws.cell(row=header_row, column=col)
                cell.value = header.replace('_', ' ').title()
                cell.font = Font(bold=True)
                cell.fill = PatternFill(start_color='D3D3D3', end_color='D3D3D3', fill_type='solid')
                cell.alignment = Alignment(horizontal='center')
            
            # Add data
            for row_idx, (_, row_data) in enumerate(df.iterrows(), 3):
                for col_idx, value in enumerate(row_data, 1):
                    cell = ws.cell(row=row_idx, column=col_idx)
                    if isinstance(value, float):
                        cell.value = round(value, 6)
                    else:
                        cell.value = value
                    cell.alignment = Alignment(horizontal='center')
            
            # Auto-adjust column widths
            for col_idx in range(1, len(headers) + 1):
                max_length = 0
                column_letter = chr(64 + col_idx)  # A, B, C, etc.
                
                # Check header length
                header_length = len(str(headers[col_idx - 1]))
                if header_length > max_length:
                    max_length = header_length
                
                # Check data lengths
                for row_idx in range(len(df)):
                    try:
                        cell_value = df.iloc[row_idx, col_idx - 1]
                        cell_length = len(str(cell_value))
                        if cell_length > max_length:
                            max_length = cell_length
                    except:
                        pass
                
                adjusted_width = min(max_length + 2, 20)
                ws.column_dimensions[column_letter].width = adjusted_width
            
            # Save the workbook
            wb.save(self.filepath)
            print(f"Excel Logger: Successfully saved {self.filepath}")
            
        except Exception as e:
            print(f"Excel Logger ERROR: Could not save Excel metrics file {self.filepath}: {e}")
            import traceback
            traceback.print_exc()

# Create directories if they don't exist
os.makedirs(SEGMENTED_IMAGES_PATH, exist_ok=True)
os.makedirs(METRICS_PATH, exist_ok=True)

# Memory management configuration (adjust for full dataset; lower if memory-constrained)
MEMORY_CONFIG = {
    'max_patients': 15,            # Reduce number of patients for memory
    'train_patients': 10,          # Reduce training patients
    'batch_size': 2,               # Lower batch size
    'max_slices_per_patient': 5,   # Fewer slices per patient
    'max_slices_evaluation': 5,    # Fewer slices for evaluation
    'training_batch_size': 2,      # Lower training batch size
    'prediction_batch_size': 2,    # Lower prediction batch size
    'max_epochs': 20,              # Fewer epochs for quick test
    'epoch_schedule': []           # No milestone training, just continuous
}

# Confidence Enhancement Configuration
CONFIDENCE_CONFIG = {
    'data_augmentation_strength': 0.3,      # Increase training data variety
    'contrast_enhancement': True,           # Enhance image contrast
    'focal_loss_gamma': 2.0,               # Use focal loss for better confidence
    'confidence_threshold_adjustment': 0.3, # Lower threshold for initial detection
    'ensemble_models': True,                # Use multiple models for voting
    'temperature_scaling': True,            # Calibrate confidence scores
}

# =============================================================================
# UI PIPELINE SETTINGS AND HELPERS
# =============================================================================

UI_PIPELINE_CONFIG = {
    'input_min_size': 96,
    'intensity_std_threshold': 5.0,
    'target_size': (240, 240),
    'classification_threshold': 0.5,  # Lowered for better detection
    'segmentation_threshold': 0.3,     # Lowered for better segmentation
    'classification_model_path': None,  # No separate classifier - using segmentation
    'segmentation_model_path': os.path.join(ROOT_DIR, "Files", "improved_simple_cnn_11_20.keras"),
    'survival_model_path': None,  # Not available yet
}

MODEL_CACHE = {}


def load_keras_model_cached(model_path, compile_model=False):
    """Load a Keras model once and cache it for subsequent calls."""
    if not model_path:
        return None
    if not os.path.exists(model_path):
        print(f"Model not found at {model_path}")
        return None
    if model_path in MODEL_CACHE:
        return MODEL_CACHE[model_path]
    try:
        model = tf.keras.models.load_model(model_path, compile=compile_model)
        MODEL_CACHE[model_path] = model
        print(f"Loaded model: {model_path}")
        return model
    except Exception as exc:
        print(f"Failed to load model {model_path}: {exc}")
        return None


def validate_input_image(image_path):
    """Validate uploaded image and ensure it resembles an MRI slice."""
    metadata = {}
    if not image_path:
        return {
            'is_valid': False,
            'message': 'No image path provided',
            'metadata': metadata,
            'image_array': None
        }
    if not os.path.exists(image_path):
        return {
            'is_valid': False,
            'message': 'File not found',
            'metadata': metadata,
            'image_array': None
        }
    try:
        with Image.open(image_path) as img:
            metadata['format'] = img.format
            metadata['mode'] = img.mode
            grayscale_image = img.convert('L')
            image_array = np.array(grayscale_image)
    except Exception as exc:
        return {
            'is_valid': False,
            'message': f'Could not read image: {exc}',
            'metadata': metadata,
            'image_array': None
        }

    if image_array.ndim != 2:
        return {
            'is_valid': False,
            'message': 'Image is not single-channel after grayscale conversion',
            'metadata': metadata,
            'image_array': None
        }

    height, width = image_array.shape
    metadata['height'] = int(height)
    metadata['width'] = int(width)
    metadata['channels'] = 1
    metadata['intensity_mean'] = float(np.mean(image_array))
    metadata['intensity_std'] = float(np.std(image_array))
    metadata['intensity_min'] = float(np.min(image_array))
    metadata['intensity_max'] = float(np.max(image_array))

    if height < UI_PIPELINE_CONFIG['input_min_size'] or width < UI_PIPELINE_CONFIG['input_min_size']:
        return {
            'is_valid': False,
            'message': 'Image dimensions are smaller than expected for MRI',
            'metadata': metadata,
            'image_array': image_array
        }

    if metadata['intensity_std'] < UI_PIPELINE_CONFIG['intensity_std_threshold']:
        return {
            'is_valid': False,
            'message': 'Low intensity variation detected. Image likely not an MRI slice.',
            'metadata': metadata,
            'image_array': image_array
        }

    metadata['validation_timestamp'] = datetime.datetime.now().isoformat()
    return {
        'is_valid': True,
        'message': 'Image passes basic MRI validation checks',
        'metadata': metadata,
        'image_array': image_array.astype(np.float32)
    }


def preprocess_mri_for_classification(image_array, target_size=None):
    """Preprocess image for classification models (single-channel)."""
    target_size = target_size or UI_PIPELINE_CONFIG['target_size']
    resized = cv2.resize(image_array, target_size, interpolation=cv2.INTER_LINEAR)
    normalized = resized / 255.0
    mean = np.mean(normalized)
    std = np.std(normalized)
    if std > 0:
        normalized = (normalized - mean) / std
    normalized = np.expand_dims(normalized, axis=-1)
    normalized = np.expand_dims(normalized, axis=0)
    return normalized.astype(np.float32)


def preprocess_mri_for_segmentation(image_array, target_size=None):
    """Preprocess image for segmentation models (stacked two-channel input)."""
    target_size = target_size or UI_PIPELINE_CONFIG['target_size']
    resized = cv2.resize(image_array, target_size, interpolation=cv2.INTER_LINEAR)
    resized = resized.astype(np.float32)
    min_val = np.min(resized)
    max_val = np.max(resized)
    if max_val > min_val:
        resized = (resized - min_val) / (max_val - min_val)
    stacked = np.stack([resized, resized], axis=-1)
    batch = np.expand_dims(stacked, axis=0)
    return batch.astype(np.float32), resized


def _infer_class_names(pred_vector):
    """Infer class labels based on output dimensions."""
    length = len(pred_vector)
    if length == 1:
        # Binary output (sigmoid) - interpret as tumor probability
        return ['No Tumor', 'Tumor']
    if length == 2:
        return ['No Tumor', 'Tumor']
    if length == 3:
        return ['No Tumor', 'Glioma', 'Meningioma']
    if length == 4:
        return ['No Tumor', 'Glioma', 'Meningioma', 'Pituitary']
    # For any other length, use generic labels
    return ['No Tumor'] + [f'Tumor Type {i}' for i in range(1, length)]


def run_classification_stage(image_batch, model_path=None, threshold=None):
    """Execute tumor classification model and return prediction details.

    Robustness:
    - If model output shape is not a small 1D vector (1-6 classes), skip classification.
    - Prevents cases like "class 8067" with misleading high confidence.
    """
    threshold = threshold or UI_PIPELINE_CONFIG['classification_threshold']
    model_path = model_path or UI_PIPELINE_CONFIG['classification_model_path']

    result = {
        'success': False,
        'message': '',
        'tumor_detected': None,
        'predicted_label': 'Unknown',
        'confidence': 0.0,
        'class_probabilities': {},
        'model_path': model_path
    }

    # If no classification model is available, skip this stage
    if not model_path:
        result['message'] = 'No classification model configured. Using segmentation for detection.'
        result['success'] = True  # Not an error, just skipping
        result['inference_method'] = 'skipped_no_classifier'
        return result

    model = load_keras_model_cached(model_path)
    if model is None:
        result['message'] = 'Classification model unavailable. Falling back to segmentation-based detection.'
        result['success'] = True  # Not an error, just skipping
        result['inference_method'] = 'skipped_model_unavailable'
        return result

    # Validate model output shape: must be (batch, C) where 1 <= C <= 6
    try:
        out_shape = getattr(model, 'output_shape', None)
        if out_shape is not None:
            # Normalize to tuple, e.g., (None, C) or (None, H, W, C)
            if isinstance(out_shape, (list, tuple)):
                shape_tuple = out_shape if isinstance(out_shape, tuple) else tuple(out_shape)
                # If output has rank >= 3 (e.g., HxW map) or too many classes, treat as invalid classifier
                if (len(shape_tuple) >= 3) or (len(shape_tuple) == 2 and shape_tuple[1] is not None and shape_tuple[1] > 10):
                    result.update({
                        'success': True,
                        'message': f'Classification model output shape {out_shape} not suitable for class prediction. Skipping.',
                        'warning': 'invalid_classifier_output_shape',
                        'inference_method': 'skipped_invalid_classifier'
                    })
                    return result
    except Exception:
        # If we can't read output shape, proceed but will still guard by predictions size
        pass

    try:
        predictions = model.predict(image_batch, verbose=0)[0]

        # Guard against non-1D outputs or excessive class counts
        if (hasattr(predictions, 'ndim') and predictions.ndim != 1) or (predictions.size > 10):
            result.update({
                'success': True,
                'message': f'Classifier produced output of shape {getattr(predictions, "shape", None)} (size={predictions.size}). Skipping classification.',
                'warning': 'invalid_classifier_output',
                'inference_method': 'skipped_invalid_output',
                'class_probabilities': {}
            })
            return result

        # Handle binary output (sigmoid activation)
        if len(predictions.shape) == 0 or predictions.size == 1:
            tumor_prob = float(predictions) if predictions.size == 1 else float(predictions)
            class_names = ['No Tumor', 'Tumor']
            probabilities = {
                'No Tumor': 1.0 - tumor_prob,
                'Tumor': tumor_prob
            }
            predicted_index = 1 if tumor_prob >= 0.5 else 0
            confidence = tumor_prob if tumor_prob >= 0.5 else (1.0 - tumor_prob)
            predicted_label = class_names[predicted_index]
        else:
            # Multi-class output (softmax) with a small number of classes
            class_names = _infer_class_names(predictions)
            probabilities = {class_names[i]: float(predictions[i]) for i in range(len(predictions))}
            predicted_index = int(np.argmax(predictions))
            confidence = float(np.max(predictions))
            predicted_label = class_names[predicted_index]

        tumor_detected = predicted_label != 'No Tumor'

        # Lower threshold for detection to be more sensitive
        detection_threshold = min(threshold, 0.5)

        if confidence < detection_threshold:
            result.update({
                'success': False,
                'message': f'Low confidence ({confidence:.2%}). Image may not be a valid MRI scan.',
                'tumor_detected': None,
                'predicted_label': predicted_label,
                'confidence': confidence,
                'class_probabilities': probabilities,
                'inference_method': 'low_confidence_classifier'
            })
        else:
            result.update({
                'success': True,
                'message': 'Classification completed successfully',
                'tumor_detected': tumor_detected,
                'predicted_label': predicted_label,
                'confidence': confidence,
                'class_probabilities': probabilities,
                'inference_method': 'classifier'
            })
    except Exception as exc:
        result.update({
            'success': False,
            'message': f'Classification failed: {exc}',
            'warning': 'classifier_exception'
        })
        import traceback
        traceback.print_exc()

    return result


def run_segmentation_stage(segmentation_batch, reference_image, model_path=None, threshold=None):
    """Run segmentation model and produce binary mask and probability map."""
    threshold = threshold or UI_PIPELINE_CONFIG['segmentation_threshold']
    model_path = model_path or UI_PIPELINE_CONFIG['segmentation_model_path']
    model = load_keras_model_cached(model_path)

    result = {
        'success': False,
        'message': '',
        'mask': None,
        'probability_map': None,
        'coverage': 0.0,
        'non_zero_pixels': 0,
        'model_path': model_path
    }

    if model is None:
        result['message'] = 'Segmentation model unavailable.'
        return result

    try:
        raw_prediction = model.predict(segmentation_batch, verbose=0)[0]
        if raw_prediction.ndim == 3:
            raw_prediction = raw_prediction[:, :, 0]
        probability_map = np.clip(raw_prediction.astype(np.float32), 0.0, 1.0)
        
        # Apply post-processing to reduce noise
        # Morphological opening to remove small false positives
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        prob_uint8 = (probability_map * 255).astype(np.uint8)
        prob_uint8 = cv2.morphologyEx(prob_uint8, cv2.MORPH_OPEN, kernel)
        probability_map = prob_uint8.astype(np.float32) / 255.0
        
        mask = (probability_map >= threshold).astype(np.uint8)
        coverage = float(mask.sum() / mask.size)

        result.update({
            'success': True,
            'message': 'Segmentation completed successfully',
            'mask': mask,
            'probability_map': probability_map,
            'coverage': coverage,
            'non_zero_pixels': int(mask.sum()),
            'reference_image': reference_image
        })
    except Exception as exc:
        result['message'] = f'Segmentation failed: {exc}'
        import traceback
        traceback.print_exc()

    return result


def extract_radiomic_features(mask, probability_map, intensity_image):
    """Extract basic radiomic and geometric features from segmentation mask."""
    if mask is None or intensity_image is None:
        return {
            'tumor_present': False,
            'message': 'No tumor region detected for feature extraction.'
        }
    
    # Check if mask has any tumor pixels (with minimum threshold)
    tumor_pixels = mask.sum()
    if tumor_pixels < 20:  # Minimum 20 pixels to consider as tumor
        return {
            'tumor_present': False,
            'message': 'No significant tumor region detected (< 20 pixels).'
        }

    try:
        labeled = measure.label(mask)
        regions = measure.regionprops(labeled, intensity_image=intensity_image)
    except:
        # Fallback if measure is not available
        return {
            'tumor_present': True,
            'total_area_pixels': int(tumor_pixels),
            'tumor_coverage_pct': float(tumor_pixels / mask.size * 100),
            'max_confidence': float(np.max(probability_map)) if probability_map is not None else 0.5,
            'mean_confidence': float(np.mean(probability_map[mask == 1])) if probability_map is not None and tumor_pixels > 0 else 0.5
        }
    
    if not regions:
        return {
            'tumor_present': False,
            'message': 'Connected component analysis found no regions.'
        }

    largest_region = max(regions, key=lambda region: region.area)
    total_area = int(mask.sum())
    coverage_pct = float(total_area / mask.size * 100)
    max_prob = float(np.max(probability_map)) if probability_map is not None else None
    mean_prob = float(np.mean(probability_map[mask == 1])) if probability_map is not None and mask.sum() > 0 else None

    features = {
        'tumor_present': True,
        'num_regions': len(regions),
        'total_area_pixels': total_area,
        'tumor_coverage_pct': coverage_pct,
        'largest_region_area': int(largest_region.area),
        'largest_region_eccentricity': float(largest_region.eccentricity),
        'largest_region_solidity': float(largest_region.solidity),
        'largest_region_centroid': (
            float(largest_region.centroid[1]),
            float(largest_region.centroid[0])
        ),
        'bounding_box': tuple(int(v) for v in largest_region.bbox),
        'mean_intensity': float(largest_region.mean_intensity),
        'max_confidence': max_prob,
        'mean_confidence': mean_prob
    }

    return features


def predict_survival_from_features(features, patient_age=None, model_path=None):
    """Predict survival category using ML model or heuristic if unavailable."""
    model_path = model_path or UI_PIPELINE_CONFIG['survival_model_path']
    model = load_keras_model_cached(model_path)

    result = {
        'success': False,
        'message': '',
        'predicted_survival': None,
        'confidence': None,
        'model_path': model_path
    }

    survival_categories = ['Short-term (<10 months)', 'Mid-term (10-15 months)', 'Long-term (>15 months)']

    if model is not None:
        try:
            feature_vector = [
                features.get('total_area_pixels', 0.0) / 1000.0,
                features.get('tumor_coverage_pct', 0.0) / 100.0,
                features.get('largest_region_eccentricity', 0.0),
                features.get('largest_region_solidity', 0.0),
                patient_age / 100.0 if patient_age is not None else 0.5,
            ]
            predictions = model.predict(np.expand_dims(feature_vector, axis=0), verbose=0)[0]
            predicted_index = int(np.argmax(predictions))
            confidence = float(np.max(predictions))
            result.update({
                'success': True,
                'predicted_survival': survival_categories[predicted_index],
                'confidence': confidence,
                'message': 'Survival prediction generated from trained model',
                'probabilities': {survival_categories[i]: float(predictions[i]) for i in range(len(predictions))}
            })
            return result
        except Exception as exc:
            result['message'] = f'Survival model inference failed: {exc}'

    # Heuristic fallback
    tumor_area = features.get('total_area_pixels', 0)
    coverage_pct = features.get('tumor_coverage_pct', 0.0)
    if patient_age is None:
        patient_age = 55.0

    risk_score = (tumor_area / 4000.0) + (coverage_pct / 80.0) + ((patient_age - 45.0) / 40.0)
    if risk_score < 0.8:
        category = survival_categories[2]
        confidence = 0.6
    elif risk_score < 1.4:
        category = survival_categories[1]
        confidence = 0.55
    else:
        category = survival_categories[0]
        confidence = 0.5

    result.update({
        'success': True,
        'predicted_survival': category,
        'confidence': confidence,
        'message': 'Heuristic survival estimate (model unavailable)'
    })
    return result


def summarize_analysis(classification, segmentation, survival, validation_message):
    """Summarize the overall pipeline findings."""
    summary = {
        'pipeline_message': validation_message,
        'tumor_present': None,
        'primary_label': None,
        'tumor_type': None,
        'confidence': None,
        'confidence_level': None,
        'recommendations': [],
        'warnings': []
    }

    # Extract tumor detection and type information
    if classification.get('success') and classification.get('tumor_detected') is not None:
        summary['tumor_present'] = bool(classification['tumor_detected'])
        summary['primary_label'] = classification.get('predicted_label', 'Unknown')
        summary['confidence'] = float(classification.get('confidence', 0.0))
        
        # Extract specific tumor type if present
        if summary['tumor_present'] and summary['primary_label'] != 'Tumor':
            summary['tumor_type'] = summary['primary_label']
        elif summary['tumor_present']:
            summary['tumor_type'] = 'Tumor (type not specified)'
    elif segmentation.get('success'):
        has_tumor = segmentation.get('non_zero_pixels', 0) > 20
        summary['tumor_present'] = has_tumor
        summary['primary_label'] = 'Tumor detected' if has_tumor else 'No Tumor'
        summary['confidence'] = float(segmentation.get('coverage', 0.0))
    else:
        summary['tumor_present'] = None
        summary['primary_label'] = 'Analysis Inconclusive'
        summary['confidence'] = 0.0

    # Confidence level description
    conf = summary.get('confidence', 0.0)
    if conf >= 0.85:
        summary['confidence_level'] = 'High Confidence'
    elif conf >= 0.65:
        summary['confidence_level'] = 'Moderate Confidence'
    elif conf >= 0.45:
        summary['confidence_level'] = 'Low Confidence'
    else:
        summary['confidence_level'] = 'Very Low Confidence'

    # Add warnings from classification
    if classification.get('warning'):
        summary['warnings'].append(classification['warning'])

    # Generate recommendations based on findings
    if summary['tumor_present']:
        summary['recommendations'].extend([
            f"Tumor Type: {summary.get('tumor_type', 'Not specified')}",
            f"Detection Confidence: {summary['confidence']:.1%} ({summary['confidence_level']})",
            'Recommended Actions:',
            '  - Review with radiologist for confirmation',
            '  - Correlate with clinical symptoms',
            '  - Consider additional imaging (contrast-enhanced MRI)',
            '  - Neuro-oncology consultation recommended'
        ])
        
        if segmentation.get('success') and segmentation.get('non_zero_pixels', 0) > 100:
            summary['recommendations'].append('  - Segmentation mask available for surgical planning')
            
    elif summary['tumor_present'] is False:
        summary['recommendations'].extend([
            f"No Tumor Detected (Confidence: {summary['confidence']:.1%})",
            'Recommended Actions:',
            '  - Routine clinical follow-up as needed',
            '  - If symptoms persist, consider repeat imaging'
        ])
    else:
        summary['recommendations'].extend([
            'Analysis Inconclusive',
            'Possible reasons:',
            '  - Image quality insufficient',
            '  - Image is not a brain MRI',
            '  - Unusual scan orientation or artifacts',
            'Recommended Actions:',
            '  - Provide standard brain MRI scan (T1/T2/FLAIR)',
            '  - Ensure image is properly oriented',
            '  - Check image quality and resolution'
        ])

    # Add survival prediction if available
    if survival.get('success') and survival.get('predicted_survival') and summary['tumor_present']:
        surv_pred = survival.get('predicted_survival')
        surv_conf = survival.get('confidence', 0.0)
        summary['recommendations'].append(f"  - Survival Estimate: {surv_pred} (Confidence: {surv_conf:.1%})")
        summary['recommendations'].append('    Note: Survival estimates are statistical averages, not individual predictions')

    return summary


def analyze_uploaded_image(
    image_path,
    patient_age=None,
    classification_model_path=None,
    segmentation_model_path=None,
    survival_model_path=None,
    return_intermediate=False
):
    """Full pipeline: validation -> classification -> segmentation -> features -> survival."""
    validation = validate_input_image(image_path)
    if not validation['is_valid']:
        return {
            'success': False,
            'stage': 'validation',
            'message': validation['message'],
            'validation': validation
        }

    image_array = validation['image_array']
    target_size = UI_PIPELINE_CONFIG['target_size']

    classification_batch = preprocess_mri_for_classification(image_array, target_size)
    segmentation_batch, reference_image = preprocess_mri_for_segmentation(image_array, target_size)

    classification_result = run_classification_stage(
        classification_batch,
        model_path=classification_model_path or UI_PIPELINE_CONFIG['classification_model_path'],
        threshold=UI_PIPELINE_CONFIG['classification_threshold']
    )

    segmentation_result = run_segmentation_stage(
        segmentation_batch,
        reference_image,
        model_path=segmentation_model_path or UI_PIPELINE_CONFIG['segmentation_model_path'],
        threshold=UI_PIPELINE_CONFIG['segmentation_threshold']
    )

    features = extract_radiomic_features(
        segmentation_result.get('mask'),
        segmentation_result.get('probability_map'),
        segmentation_result.get('reference_image')
    )

    # Improved inference logic using both classification and segmentation
    # Priority: Use classification if confident, otherwise use segmentation
    
    classification_confident = classification_result.get('success') and classification_result.get('confidence', 0) > 0.5
    segmentation_has_tumor = features.get('tumor_present', False)
    
    if not classification_confident:
        # Classification failed or low confidence - use segmentation
        if segmentation_has_tumor:
            # Estimate tumor type from segmentation features
            tumor_area = features.get('total_area_pixels', 0)
            coverage = features.get('tumor_coverage_pct', 0)
            eccentricity = features.get('largest_region_eccentricity', 0.5)
            
            # Heuristic tumor type estimation based on shape and size
            if tumor_area > 2000 and coverage > 15:
                tumor_type = 'Glioma (likely high-grade)'
            elif tumor_area > 1000 and eccentricity < 0.5:
                tumor_type = 'Meningioma (compact shape)'
            elif tumor_area < 800 and coverage < 8:
                tumor_type = 'Pituitary adenoma (small, localized)'
            else:
                tumor_type = 'Glioma (moderate grade)'
            
            classification_result.update({
                'success': True,
                'tumor_detected': True,
                'predicted_label': tumor_type,
                'confidence': min(0.75, features.get('mean_confidence', 0.6)),
                'message': 'Tumor type inferred from segmentation features (classification model unavailable or low confidence)',
                'inference_method': 'segmentation_based'
            })
        else:
            classification_result.update({
                'success': True,
                'tumor_detected': False,
                'predicted_label': 'No Tumor',
                'confidence': 0.85,
                'message': 'No tumor detected in segmentation analysis',
                'inference_method': 'segmentation_based'
            })
    else:
        # Classification is confident - verify with segmentation
        classification_says_tumor = classification_result.get('tumor_detected', False)
        
        if classification_says_tumor and not segmentation_has_tumor:
            # Classification says tumor but segmentation doesn't find it - low confidence
            classification_result.update({
                'confidence': min(classification_result.get('confidence', 0.5), 0.6),
                'message': 'Classification detected tumor but segmentation did not confirm. Use caution.',
                'warning': 'Discrepancy between classification and segmentation'
            })
        elif not classification_says_tumor and segmentation_has_tumor:
            # Segmentation found tumor but classification didn't - override classification
            tumor_area = features.get('total_area_pixels', 0)
            classification_result.update({
                'tumor_detected': True,
                'predicted_label': 'Tumor detected (segmentation override)',
                'confidence': 0.65,
                'message': 'Segmentation found tumor region despite classification saying no tumor',
                'warning': 'Segmentation override applied'
            })

    survival_result = predict_survival_from_features(
        features,
        patient_age=patient_age,
        model_path=survival_model_path or UI_PIPELINE_CONFIG['survival_model_path']
    )

    summary = summarize_analysis(classification_result, segmentation_result, survival_result, validation['message'])

    response = {
        'success': True,
        'stage': 'completed',
        'validation': validation,
        'classification': classification_result,
        'segmentation': segmentation_result,
        'features': features,
        'survival': survival_result,
        'summary': summary
    }

    if not return_intermediate:
        # Remove large arrays before returning to UI layer
        if 'reference_image' in response['segmentation']:
            response['segmentation'].pop('reference_image', None)
        if 'probability_map' in response['segmentation']:
            response['segmentation'].pop('probability_map', None)
        if 'mask' in response['segmentation']:
            response['segmentation']['mask'] = int(response['segmentation']['non_zero_pixels'] > 0)

    return response

def focal_loss(gamma=2.0, alpha=0.25):
    """
    Focal Loss for addressing class imbalance and improving confidence
    Helps model focus on hard examples and improves prediction confidence
    """
    def focal_loss_fixed(y_true, y_pred):
        epsilon = tf.keras.backend.epsilon()
        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)
        
        # Calculate focal loss
        alpha_t = y_true * alpha + (1 - y_true) * (1 - alpha)
        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)
        focal_loss = -alpha_t * tf.pow((1 - p_t), gamma) * tf.log(p_t)
        
        return tf.reduce_mean(focal_loss)
    
    return focal_loss_fixed

def enhance_image_contrast(image, contrast_factor=1.5):
    """
    Enhance image contrast to improve model confidence
    """
    # Normalize to 0-1 range
    image_normalized = (image - np.min(image)) / (np.max(image) - np.min(image) + 1e-8)
    
    # Apply contrast enhancement
    enhanced = np.power(image_normalized, 1.0 / contrast_factor)
    
    # Apply histogram equalization for better contrast
    enhanced = (enhanced * 255).astype(np.uint8)
    enhanced = cv2.equalizeHist(enhanced)
    enhanced = enhanced.astype(np.float32) / 255.0
    
    return enhanced

def confidence_weighted_prediction(predictions, confidence_threshold=0.3):
    """
    Apply confidence weighting to improve prediction reliability
    """
    # Calculate confidence weights based on prediction certainty
    confidence_weights = np.abs(predictions - 0.5) * 2  # Distance from uncertain (0.5)
    
    # Apply temperature scaling for better calibration
    temperature = 1.5
    calibrated_predictions = 1 / (1 + np.exp(-np.log(predictions / (1 - predictions + 1e-8)) / temperature))
    
    # Weight predictions by confidence
    weighted_predictions = calibrated_predictions * (0.5 + confidence_weights * 0.5)
    
    return weighted_predictions

# Step 1: Data Loading and Preprocessing
def create_high_confidence_model(input_shape=(240, 240, 2), num_classes=1):
    """
    Create an enhanced model with better confidence predictions
    """
    inputs = Input(input_shape)
    
    # Enhanced encoder with more filters for better feature extraction
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)
    conv1 = BatchNormalization()(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    drop1 = Dropout(0.2)(pool1)
    
    conv2 = Conv2D(128, 3, activation='relu', padding='same')(drop1)
    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)
    conv2 = BatchNormalization()(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    drop2 = Dropout(0.2)(pool2)
    
    conv3 = Conv2D(256, 3, activation='relu', padding='same')(drop2)
    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)
    conv3 = BatchNormalization()(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    drop3 = Dropout(0.3)(pool3)
    
    # Bottleneck with attention
    conv4 = Conv2D(512, 3, activation='relu', padding='same')(drop3)
    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)
    conv4 = BatchNormalization()(conv4)
    drop4 = Dropout(0.3)(conv4)
    
    # Enhanced decoder with attention gates
    up1 = Conv2D(256, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop4))
    att1 = attention_gate(conv3, up1, filters=256)
    merge1 = concatenate([att1, up1], axis=3)
    conv5 = Conv2D(256, 3, activation='relu', padding='same')(merge1)
    conv5 = Conv2D(256, 3, activation='relu', padding='same')(conv5)
    conv5 = BatchNormalization()(conv5)
    drop5 = Dropout(0.2)(conv5)
    
    up2 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop5))
    att2 = attention_gate(conv2, up2, filters=128)
    merge2 = concatenate([att2, up2], axis=3)
    conv6 = Conv2D(128, 3, activation='relu', padding='same')(merge2)
    conv6 = Conv2D(128, 3, activation='relu', padding='same')(conv6)
    conv6 = BatchNormalization()(conv6)
    drop6 = Dropout(0.2)(conv6)
    
    up3 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop6))
    att3 = attention_gate(conv1, up3, filters=64)
    merge3 = concatenate([att3, up3], axis=3)
    conv7 = Conv2D(64, 3, activation='relu', padding='same')(merge3)
    conv7 = Conv2D(64, 3, activation='relu', padding='same')(conv7)
    conv7 = BatchNormalization()(conv7)
    
    # Confidence enhancement layers
    confidence_conv = Conv2D(32, 3, activation='relu', padding='same')(conv7)
    confidence_conv = BatchNormalization()(confidence_conv)
    confidence_conv = Conv2D(16, 3, activation='relu', padding='same')(confidence_conv)
    confidence_conv = BatchNormalization()(confidence_conv)
    
    # Final output with sigmoid activation
    outputs = Conv2D(num_classes, 1, activation='sigmoid')(confidence_conv)
    
    model = Model(inputs=inputs, outputs=outputs)
    
    # Use focal loss for better confidence
    model.compile(
        optimizer=Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999),
        loss=focal_loss(gamma=CONFIDENCE_CONFIG['focal_loss_gamma']),
        metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), F1Score(), f1_score_metric]
    )
    
    return model

def apply_confidence_boosting_techniques(X_data, y_data):
    """
    Apply various techniques to boost model confidence during training
    """
    print("ðŸš€ Applying confidence boosting techniques...")
    
    # 1. Enhance contrast for better feature visibility
    if CONFIDENCE_CONFIG['contrast_enhancement']:
        print("   âœ… Applying contrast enhancement...")
        for i in range(X_data.shape[0]):
            for channel in range(X_data.shape[3]):
                X_data[i, :, :, channel] = enhance_image_contrast(
                    X_data[i, :, :, channel], 
                    contrast_factor=1.5
                )
    
    # 2. Data augmentation for more robust training
    if CONFIDENCE_CONFIG['data_augmentation_strength'] > 0:
        print("   âœ… Applying data augmentation...")
        augmented_X = []
        augmented_y = []
        
        for i in range(len(X_data)):
            # Original data
            augmented_X.append(X_data[i])
            augmented_y.append(y_data[i])
            
            # Augmented versions
            strength = CONFIDENCE_CONFIG['data_augmentation_strength']
            
            # Rotation
            angle = np.random.uniform(-15 * strength, 15 * strength)
            augmented_image = rotate(X_data[i], angle, reshape=False, mode='reflect')
            augmented_mask = rotate(y_data[i], angle, reshape=False, mode='reflect')
            augmented_X.append(augmented_image)
            augmented_y.append(augmented_mask)
            
            # Brightness adjustment
            brightness_factor = np.random.uniform(0.8, 1.2)
            bright_image = np.clip(X_data[i] * brightness_factor, 0, 1)
            augmented_X.append(bright_image)
            augmented_y.append(y_data[i])
        
        X_data = np.array(augmented_X)
        y_data = np.array(augmented_y)
        print(f"   ðŸ“ˆ Dataset expanded to {len(X_data)} samples")
    
    return X_data, y_data

def ensemble_prediction_for_confidence(models, X_test):
    """
    Use ensemble of models to increase prediction confidence
    """
    print("ðŸ¤– Running ensemble prediction for higher confidence...")
    
    all_predictions = []
    
    for i, model in enumerate(models):
        print(f"   Model {i+1}/{len(models)} predicting...")
        predictions = model.predict(X_test, batch_size=2, verbose=0)
        all_predictions.append(predictions)
    
    # Average predictions for ensemble
    ensemble_pred = np.mean(all_predictions, axis=0)
    
    # Calculate confidence based on agreement between models
    model_agreement = np.std(all_predictions, axis=0)  # Lower std = higher agreement
    confidence_boost = 1 - (model_agreement / np.max(model_agreement))  # Higher agreement = higher confidence
    
    # Apply confidence boost
    boosted_predictions = ensemble_pred * (0.7 + 0.3 * confidence_boost)
    
    return boosted_predictions, confidence_boost

def load_patient_data(patient_folder):
    """Load T2 and FLAIR modalities for a patient with memory-efficient loading"""
    patient_id = os.path.basename(patient_folder)
    
    # Load T2 and FLAIR images - BraTS naming convention
    t2_path = os.path.join(patient_folder, f"{patient_id}_t2.nii")
    flair_path = os.path.join(patient_folder, f"{patient_id}_flair.nii")
    seg_path = os.path.join(patient_folder, f"{patient_id}_seg.nii")
    
    # Check if segmentation exists (validation data may not have ground truth)
    has_segmentation = os.path.exists(seg_path)
    
    print(f"Loading {t2_path}")
    print(f"Loading {flair_path}")
    if has_segmentation:
        print(f"Loading {seg_path}")
    else:
        print(f"No segmentation file found (validation data)")
    
    try:
        # Load data using memory mapping to avoid loading entire arrays into memory
        t2_img = nib.load(t2_path)
        flair_img = nib.load(flair_path)
        
        # Load segmentation only if it exists
        if has_segmentation:
            seg_img = nib.load(seg_path)
        
        # Get data in smaller chunks to avoid memory issues
        # Load only a small portion of the volume to reduce memory usage
        z_size = t2_img.shape[2]
        start_z = max(0, z_size // 3)
        end_z = min(z_size, 2 * z_size // 3)
        
        # Load data in chunks - smaller chunks for memory efficiency
        chunk_size = min(5, end_z - start_z)  # Load max 5 slices at a time
        t2_chunks = []
        flair_chunks = []
        seg_chunks = []
        
        for z_start in range(start_z, end_z, chunk_size):
            z_end = min(z_start + chunk_size, end_z)
            
            # Load chunk and convert to float32
            t2_chunk = t2_img.dataobj[:, :, z_start:z_end].astype(np.float32)
            flair_chunk = flair_img.dataobj[:, :, z_start:z_end].astype(np.float32)
            
            t2_chunks.append(t2_chunk)
            flair_chunks.append(flair_chunk)
            
            if has_segmentation:
                seg_chunk = seg_img.dataobj[:, :, z_start:z_end].astype(np.float32)
                seg_chunks.append(seg_chunk)
                # Clear chunk from memory immediately
                del t2_chunk, flair_chunk, seg_chunk
            else:
                # Clear chunk from memory immediately
                del t2_chunk, flair_chunk
            
            gc.collect()
        
        # Concatenate chunks
        t2_img = np.concatenate(t2_chunks, axis=2)
        flair_img = np.concatenate(flair_chunks, axis=2)
        
        if has_segmentation:
            seg_img = np.concatenate(seg_chunks, axis=2)
            # Clear chunks from memory
            del t2_chunks, flair_chunks, seg_chunks
            print(f"Loaded data shapes - T2: {t2_img.shape}, FLAIR: {flair_img.shape}, Seg: {seg_img.shape}")
        else:
            seg_img = None
            # Clear chunks from memory
            del t2_chunks, flair_chunks
            print(f"Loaded data shapes - T2: {t2_img.shape}, FLAIR: {flair_img.shape}, Seg: None (validation data)")
        
        gc.collect()
        
        return t2_img, flair_img, seg_img, patient_id
        
    except Exception as e:
        print(f"Error loading files for {patient_id}: {str(e)}")
        # Try alternative file extensions
        try:
            print("Trying alternative file extensions...")
            t2_path = os.path.join(patient_folder, f"{patient_id}_t2.nii.gz")
            flair_path = os.path.join(patient_folder, f"{patient_id}_flair.nii.gz")
            seg_path = os.path.join(patient_folder, f"{patient_id}_seg.nii.gz")

            print(f"Loading {t2_path}")
            print(f"Loading {flair_path}")
            print(f"Loading {seg_path}")

            # Same chunked loading approach for compressed files
            t2_img = nib.load(t2_path)
            flair_img = nib.load(flair_path)
            seg_img = nib.load(seg_path) if has_segmentation else None

            z_size = t2_img.shape[2]
            start_z = max(0, z_size // 3)
            end_z = min(z_size, 2 * z_size // 3)

            chunk_size = min(5, end_z - start_z)  # Smaller chunks for memory efficiency
            t2_chunks = []
            flair_chunks = []
            seg_chunks = []

            for z_start in range(start_z, end_z, chunk_size):
                z_end = min(z_start + chunk_size, end_z)

                t2_chunk = t2_img.dataobj[:, :, z_start:z_end].astype(np.float32)
                flair_chunk = flair_img.dataobj[:, :, z_start:z_end].astype(np.float32)
                t2_chunks.append(t2_chunk)
                flair_chunks.append(flair_chunk)

                if has_segmentation and seg_img is not None:
                    seg_chunk = seg_img.dataobj[:, :, z_start:z_end].astype(np.float32)
                    seg_chunks.append(seg_chunk)
                    del seg_chunk

                del t2_chunk, flair_chunk
                gc.collect()

            t2_img = np.concatenate(t2_chunks, axis=2)
            flair_img = np.concatenate(flair_chunks, axis=2)
            if has_segmentation and seg_chunks:
                seg_img = np.concatenate(seg_chunks, axis=2)
            else:
                seg_img = None

            del t2_chunks, flair_chunks, seg_chunks
            gc.collect()

            print(f"Loaded data shapes - T2: {t2_img.shape}, FLAIR: {flair_img.shape}, Seg: {seg_img.shape if seg_img is not None else 'None'}")
            return t2_img, flair_img, seg_img, patient_id

        except Exception as e2:
            print(f"Error loading files with alternative extensions: {str(e2)}")
            raise

def preprocess_volume(t2_volume, flair_volume):
    """Preprocess 3D volumes"""
    # Normalize volumes
    t2_norm = (t2_volume - t2_volume.min()) / (t2_volume.max() - t2_volume.min() + 1e-8)
    flair_norm = (flair_volume - flair_volume.min()) / (flair_volume.max() - flair_volume.min() + 1e-8)
    
    # Stack T2 and FLAIR as channels
    combined = np.stack([t2_norm, flair_norm], axis=-1)
    
    return combined

def convert_3d_to_2d_slices(volume, mask=None, max_slices=None):
    """Convert 3D volume to 2D slices with memory management"""
    slices = []
    masks = []
    
    # Get middle 80% of slices (to avoid empty slices at edges)
    start_idx = int(volume.shape[2] * 0.1)
    end_idx = int(volume.shape[2] * 0.9)
    
    # Limit the number of slices if specified
    total_slices = end_idx - start_idx
    if max_slices is not None and total_slices > max_slices:
        # Sample evenly distributed slices
        step = total_slices // max_slices
        indices = range(start_idx, end_idx, step)[:max_slices]
    else:
        indices = range(start_idx, end_idx)
    
    for i in indices:
        slice_data = volume[:, :, i]
        slices.append(slice_data)
        
        if mask is not None:
            mask_slice = mask[:, :, i]
            # Convert segmentation to binary (any tumor vs no tumor)
            binary_mask = (mask_slice > 0).astype(np.float32)
            masks.append(binary_mask)
    
    return np.array(slices, dtype=np.float32), np.array(masks, dtype=np.float32) if mask is not None else None

# Step 2: Attention U-Net Model
def attention_gate(x, g, filters):
    """Attention gate for attention U-Net"""
    theta_x = Conv2D(filters, (1, 1), padding='same')(x)
    phi_g = Conv2D(filters, (1, 1), padding='same')(g)
    
    f = Activation('relu')(theta_x + phi_g)
    psi_f = Conv2D(1, (1, 1), padding='same')(f)
    
    rate = Activation('sigmoid')(psi_f)
    
    att_x = Multiply()([x, rate])
    
    return att_x

def attention_unet(input_shape=(240, 240, 2), num_classes=1):
    """Attention U-Net model architecture (simplified for memory efficiency)"""
    inputs = Input(input_shape)
    
    # Simplified encoder
    conv1 = Conv2D(32, 3, activation='relu', padding='same')(inputs)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    
    conv2 = Conv2D(64, 3, activation='relu', padding='same')(pool1)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    
    # Bottleneck
    conv3 = Conv2D(128, 3, activation='relu', padding='same')(pool2)
    drop3 = Dropout(0.3)(conv3)
    
    # Simplified decoder with attention
    up1 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop3))
    att1 = attention_gate(conv2, up1, filters=64)
    merge1 = concatenate([att1, up1], axis=3)
    conv4 = Conv2D(64, 3, activation='relu', padding='same')(merge1)
    
    up2 = Conv2D(32, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv4))
    att2 = attention_gate(conv1, up2, filters=32)
    merge2 = concatenate([att2, up2], axis=3)
    conv5 = Conv2D(32, 3, activation='relu', padding='same')(merge2)
    
    # Add confidence enhancement layer before final output
    confidence_enhance = Conv2D(16, 3, activation='relu', padding='same')(conv5)
    confidence_enhance = BatchNormalization()(confidence_enhance)
    confidence_enhance = Dropout(0.1)(confidence_enhance)
    
    outputs = Conv2D(num_classes, 1, activation='sigmoid')(confidence_enhance)
    
    model = Model(inputs=inputs, outputs=outputs)
    
    # Enhanced optimizer for better confidence
    optimizer = Adam(
        learning_rate=1e-4,
        beta_1=0.9,
        beta_2=0.999,
        epsilon=1e-8
    )
    
    model.compile(optimizer=optimizer, 
                  loss='binary_crossentropy', 
                  metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), F1Score(), f1_score_metric])
    
    return model

# Step 3: Basic CNN for comparison
def simple_cnn(input_shape=(240, 240, 2), num_classes=1):
    """Simple CNN model for comparison (simplified for memory efficiency)"""
    inputs = Input(input_shape)
    
    # Simplified encoder
    conv1 = Conv2D(32, 3, activation='relu', padding='same')(inputs)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    
    conv2 = Conv2D(64, 3, activation='relu', padding='same')(pool1)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    
    # Bottleneck
    conv3 = Conv2D(128, 3, activation='relu', padding='same')(pool2)
    
    # Simplified decoder
    up1 = UpSampling2D(size=(2, 2))(conv3)
    conv4 = Conv2D(64, 3, activation='relu', padding='same')(up1)
    
    up2 = UpSampling2D(size=(2, 2))(conv4)
    conv5 = Conv2D(32, 3, activation='relu', padding='same')(up2)
    
    outputs = Conv2D(num_classes, 1, activation='sigmoid')(conv5)
    
    model = Model(inputs=inputs, outputs=outputs)
    model.compile(optimizer=Adam(learning_rate=1e-4), 
                  loss='binary_crossentropy', 
                  metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), F1Score(), f1_score_metric])
    
    return model

# Step 4: Training and Evaluation
def create_data_generator(patient_folders, batch_size=4):
    """Create a memory-efficient data generator that loads data on-the-fly"""
    while True:
        # Shuffle patient folders
        shuffled_folders = np.random.permutation(patient_folders)
        
        for start_idx in range(0, len(shuffled_folders), batch_size):
            end_idx = min(start_idx + batch_size, len(shuffled_folders))
            batch_folders = shuffled_folders[start_idx:end_idx]
            
            batch_X = []
            batch_y = []
            
            for folder in batch_folders:
                try:
                    t2_img, flair_img, seg_img, _ = load_patient_data(folder)
                    
                    # Preprocess volumes
                    preprocessed = preprocess_volume(t2_img, flair_img)
                    
                    # Convert to 2D slices with limited number
                    slices, masks = convert_3d_to_2d_slices(preprocessed, seg_img, max_slices=MEMORY_CONFIG['max_slices_per_patient'])
                    
                    if slices.shape[0] > 0 and masks.shape[0] > 0:
                        # Add channel dimension to masks
                        masks = np.expand_dims(masks, axis=-1)
                        
                        batch_X.extend(slices)
                        batch_y.extend(masks)
                    
                    # Clear memory immediately
                    del t2_img, flair_img, seg_img, preprocessed, slices, masks
                    gc.collect()
                    
                except Exception as e:
                    print(f"Error processing {folder}: {str(e)}")
                    continue
            
            if batch_X and batch_y:
                yield np.array(batch_X), np.array(batch_y)

def train_models(train_folders, val_folders):
    """Train both models and return metrics"""
    batch_size = MEMORY_CONFIG['training_batch_size']
    max_epochs = MEMORY_CONFIG['max_epochs']

    # Generators for memory efficiency
    train_gen = create_data_generator(train_folders, batch_size)
    val_gen = create_data_generator(val_folders, batch_size)

    # Estimate steps per epoch based on number of folders and slices per patient
    estimated_slices_per_epoch = len(train_folders) * MEMORY_CONFIG['max_slices_per_patient']
    steps_per_epoch = max(1, math.ceil(estimated_slices_per_epoch / batch_size))
    
    estimated_val_slices = len(val_folders) * MEMORY_CONFIG['max_slices_per_patient']
    validation_steps = max(1, math.ceil(estimated_val_slices / batch_size))

    print(f"\n{'='*60}")
    print("STEP 1: Training Simple CNN on T2 and FLAIR modalities")
    print(f"{'='*60}")
    
    # Train simple CNN
    simple_model = simple_cnn(input_shape=(240, 240, 2))
    simple_logger = CSVLogger(os.path.join(METRICS_PATH, 'simple_cnn_training_log.csv'), append=False)
    simple_excel_logger = ExcelMetricsLogger(os.path.join(METRICS_PATH, 'simple_cnn_training_metrics.xlsx'), 'Simple CNN')
    
    # Test Excel logger creation
    print(f"Testing Excel logger creation...")
    try:
        test_wb = Workbook()
        test_path = os.path.join(METRICS_PATH, 'test_excel.xlsx')
        test_wb.save(test_path)
        print(f"âœ… Excel creation test successful: {test_path}")
        os.remove(test_path)  # Clean up test file
    except Exception as e:
        print(f"âŒ Excel creation test failed: {e}")
    
    simple_callbacks = [
        ModelCheckpoint(os.path.join(RESULTS_PATH, 'simple_cnn_best.h5'), 
                       monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),
        EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True),
        simple_logger,
        simple_excel_logger
    ]
    
    print(f"Training for {max_epochs} epochs with {steps_per_epoch} steps per epoch...")
    simple_history = simple_model.fit(
        train_gen,
        steps_per_epoch=steps_per_epoch,
        epochs=max_epochs,
        validation_data=val_gen,
        validation_steps=validation_steps,
        callbacks=simple_callbacks,
        verbose=1
    )
    
    # Save final model
    simple_model.save(os.path.join(RESULTS_PATH, 'simple_cnn_final.h5'))
    print("Simple CNN training completed!")

    print(f"\n{'='*60}")
    print("STEP 2: Training Attention U-Net to enhance segmentation")
    print(f"{'='*60}")
    
    # Train attention U-Net
    attention_model = attention_unet(input_shape=(240, 240, 2))
    attention_logger = CSVLogger(os.path.join(METRICS_PATH, 'attention_unet_training_log.csv'), append=False)
    attention_excel_logger = ExcelMetricsLogger(os.path.join(METRICS_PATH, 'attention_unet_training_metrics.xlsx'), 'Attention U-Net')
    attention_callbacks = [
        ModelCheckpoint(os.path.join(RESULTS_PATH, 'attention_unet_best.h5'), 
                       monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),
        EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True),
        attention_logger,
        attention_excel_logger
    ]
    
    print(f"Training for {max_epochs} epochs with {steps_per_epoch} steps per epoch...")
    attention_history = attention_model.fit(
        train_gen,
        steps_per_epoch=steps_per_epoch,
        epochs=max_epochs,
        validation_data=val_gen,
        validation_steps=validation_steps,
        callbacks=attention_callbacks,
        verbose=1
    )
    
    # Save final model
    attention_model.save(os.path.join(RESULTS_PATH, 'attention_unet_final.h5'))
    print("Attention U-Net training completed!")
    
    # Calculate final training metrics
    print("\nEvaluating models on validation data...")
    simple_eval = simple_model.evaluate(val_gen, steps=validation_steps, verbose=0)
    # Map metric names to values so we don't rely on a fixed number/order of metrics
    simple_metrics = dict(zip(simple_model.metrics_names, simple_eval))

    attention_eval = attention_model.evaluate(val_gen, steps=validation_steps, verbose=0)
    attention_metrics = dict(zip(attention_model.metrics_names, attention_eval))

    # Extract common metrics safely (use .get to default to None if not present)
    simple_val_loss = simple_metrics.get('loss')
    simple_val_acc = simple_metrics.get('accuracy') or simple_metrics.get('acc')
    simple_val_recall = simple_metrics.get('recall')
    simple_val_precision = simple_metrics.get('precision')

    attention_val_loss = attention_metrics.get('loss')
    attention_val_acc = attention_metrics.get('accuracy') or attention_metrics.get('acc')
    attention_val_recall = attention_metrics.get('recall')
    attention_val_precision = attention_metrics.get('precision')
    
    # Create training summary
    training_summary = {
        'simple_cnn': {
            'val_loss': simple_val_loss,
            'val_accuracy': simple_val_acc,
            'val_recall': simple_val_recall,
            'val_precision': simple_val_precision,
            'history': simple_history.history
        },
        'attention_unet': {
            'val_loss': attention_val_loss,
            'val_accuracy': attention_val_acc,
            'val_recall': attention_val_recall,
            'val_precision': attention_val_precision,
            'history': attention_history.history
        }
    }
    
    return simple_model, attention_model, simple_history.history, attention_history.history, training_summary

# Step 5: Tumor Type Detection
def detect_tumor_type(segmentation_mask):
    """Simple tumor type detection based on segmentation characteristics"""
    # This is a placeholder - in a real implementation, you would use more sophisticated methods
    # For example, analyzing the shape, size, location, and intensity patterns
    
    # Example logic:
    volume = np.sum(segmentation_mask > 0)
    if volume < 1000:
        return "Small tumor (possibly low-grade)"
    elif volume < 5000:
        return "Medium tumor"
    else:
        return "Large tumor (possibly high-grade)"

# Step 6: Evaluation and Saving Results
def evaluate_and_save(model, patient_id, original_volume, original_mask, preprocessed_volume, model_name):
    """Evaluate model on a patient volume and save results"""
    # Convert all slices for evaluation (no max_slices limit)
    slices, _ = convert_3d_to_2d_slices(preprocessed_volume, max_slices=None)
    
    # Predict on slices in batches
    batch_size = MEMORY_CONFIG['prediction_batch_size']
    predictions = []
    
    print(f"  Predicting on {len(slices)} slices for {patient_id}...")
    for i in range(0, len(slices), batch_size):
        batch_slices = slices[i:i+batch_size]
        batch_pred = model.predict(batch_slices, verbose=0)
        predictions.extend(batch_pred)
    
    predictions = np.array(predictions)
    
    # Convert predictions back to 3D volume
    # Create pred_volume with same shape as input volume
    if original_mask is not None:
        pred_volume = np.zeros_like(original_mask)
        reference_shape = original_mask.shape
    else:
        # For validation data without ground truth, use preprocessed volume shape
        reference_shape = preprocessed_volume.shape[:3]  # Take first 3 dimensions (exclude channels)
        pred_volume = np.zeros(reference_shape, dtype=np.float32)
    
    # Get middle 80% of slices (to match what we used in convert_3d_to_2d_slices)
    start_idx = int(reference_shape[2] * 0.1)
    end_idx = int(reference_shape[2] * 0.9)
    
    # Calculate actual indices used
    total_slices = end_idx - start_idx
    actual_indices = list(range(start_idx, end_idx))[:len(predictions)]
    
    for i, pred in enumerate(predictions):
        if i < len(actual_indices):
            idx = actual_indices[i]
            # Threshold prediction
            binary_pred = (pred > 0.5).astype(np.float32)
            pred_volume[:, :, idx] = binary_pred[:, :, 0]
    
    # Calculate comprehensive metrics (only if ground truth is available)
    if original_mask is not None:
        dice_score = calculate_dice_score(original_mask > 0, pred_volume > 0)
        iou_score = calculate_iou_score(original_mask > 0, pred_volume > 0)
        precision_score = calculate_precision_score(original_mask > 0, pred_volume > 0)
        recall_score = calculate_recall_score(original_mask > 0, pred_volume > 0)
        accuracy_score = calculate_accuracy_score(original_mask > 0, pred_volume > 0)
        f1_score = calculate_f1_score(original_mask > 0, pred_volume > 0)
        
        # Calculate volume metrics
        true_volume = np.sum(original_mask > 0)
        pred_volume_sum = np.sum(pred_volume > 0)
        volume_error = abs(true_volume - pred_volume_sum) / (true_volume + 1e-8)
        
        print(f"  {patient_id} - Dice: {dice_score:.4f}, IoU: {iou_score:.4f}, F1: {f1_score:.4f}, Accuracy: {accuracy_score:.4f}")
    else:
        # For validation data without ground truth
        dice_score = None
        iou_score = None
        precision_score = None
        recall_score = None
        accuracy_score = None
        f1_score = None
        true_volume = None
        pred_volume_sum = np.sum(pred_volume > 0)
        volume_error = None
        
        print(f"  {patient_id} - Prediction complete (no ground truth for validation)")
    
    # Detect tumor type
    tumor_type = detect_tumor_type(pred_volume)
    
    # Save segmented images as PNG
    # Debug: report prediction summary before saving
    try:
        nonzero = int(np.sum(pred_volume > 0))
    except Exception:
        nonzero = None
    print(f"  Debug: Prediction summary for {patient_id} (model={model_name}) - nonzero pixels: {nonzero}")

    try:
        save_segmentation_as_png(patient_id, original_volume, original_mask, pred_volume, model_name)
    except Exception as e:
        print(f"  ERROR: save_segmentation_as_png failed for {patient_id}: {e}")
        import traceback
        traceback.print_exc()
    
    # Clear memory
    del slices, predictions
    gc.collect()
    
    return {
        'patient_id': patient_id,
        'dice_score': dice_score,
        'iou_score': iou_score,
        'precision_score': precision_score,
        'recall_score': recall_score,
        'accuracy_score': accuracy_score,
        'f1_score': f1_score,
        'true_volume': int(true_volume) if true_volume is not None else None,
        'predicted_volume': int(pred_volume_sum),
        'volume_error': volume_error,
        'tumor_type': tumor_type
    }, pred_volume

def calculate_dice_score(y_true, y_pred):
    """Calculate Dice score for segmentation evaluation"""
    intersection = np.sum(y_true * y_pred)
    return (2. * intersection) / (np.sum(y_true) + np.sum(y_pred) + 1e-7)

def calculate_iou_score(y_true, y_pred):
    """Calculate Intersection over Union (IoU) score"""
    intersection = np.sum(y_true * y_pred)
    union = np.sum(y_true) + np.sum(y_pred) - intersection
    return intersection / (union + 1e-7)

def calculate_precision_score(y_true, y_pred):
    """Calculate Precision score"""
    intersection = np.sum(y_true * y_pred)
    return intersection / (np.sum(y_pred) + 1e-7)

def calculate_recall_score(y_true, y_pred):
    """Calculate Recall score"""
    intersection = np.sum(y_true * y_pred)
    return intersection / (np.sum(y_true) + 1e-7)

def calculate_accuracy_score(y_true, y_pred):
    """Calculate Accuracy score"""
    correct = np.sum(y_true == y_pred)
    total = y_true.size
    return correct / total

def calculate_f1_score(y_true, y_pred):
    """Calculate F1 score for segmentation evaluation"""
    # Calculate precision and recall
    precision = calculate_precision_score(y_true, y_pred)
    recall = calculate_recall_score(y_true, y_pred)
    
    # Calculate F1 score
    if precision + recall == 0:
        return 0.0
    
    f1 = 2 * (precision * recall) / (precision + recall)
    return f1

def create_comprehensive_report(simple_df, attention_df, training_summary):
    """Create a comprehensive Excel report with multiple sheets"""
    import datetime
    
    # Helper function to safely calculate statistics for columns with None values
    def safe_mean(series):
        return series.dropna().mean() if not series.dropna().empty else None
    
    def safe_std(series):
        return series.dropna().std() if not series.dropna().empty else None
    
    def format_metric(value):
        return f"{value:.4f}" if value is not None else "N/A (validation data)"
    
    # Create workbook
    wb = Workbook()
    
    # Remove default sheet
    wb.remove(wb.active)
    
    # Create sheets
    ws_summary = wb.create_sheet("Executive Summary")
    ws_comparison = wb.create_sheet("Patient-wise Comparison")
    ws_simple = wb.create_sheet("Simple CNN Details")
    ws_attention = wb.create_sheet("Attention U-Net Details")
    ws_training = wb.create_sheet("Training History")
    
    # Executive Summary Sheet
    ws_summary['A1'] = "Brain Tumor Segmentation - Executive Summary"
    ws_summary['A1'].font = Font(bold=True, size=16)
    ws_summary['A3'] = f"Report Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
    ws_summary['A4'] = f"Number of Patients Evaluated: {len(simple_df)}"
    
    # Add summary statistics
    simple_dice_mean = safe_mean(simple_df['dice_score'])
    attention_dice_mean = safe_mean(attention_df['dice_score'])
    simple_iou_mean = safe_mean(simple_df['iou_score'])
    attention_iou_mean = safe_mean(attention_df['iou_score'])
    simple_precision_mean = safe_mean(simple_df['precision_score'])
    attention_precision_mean = safe_mean(attention_df['precision_score'])
    simple_recall_mean = safe_mean(simple_df['recall_score'])
    attention_recall_mean = safe_mean(attention_df['recall_score'])
    simple_accuracy_mean = safe_mean(simple_df['accuracy_score'])
    attention_accuracy_mean = safe_mean(attention_df['accuracy_score'])
    simple_f1_mean = safe_mean(simple_df['f1_score'])
    attention_f1_mean = safe_mean(attention_df['f1_score'])
    
    summary_data = [
        ["Metric", "Simple CNN", "Attention U-Net", "Improvement"],
        ["Average Dice Score", format_metric(simple_dice_mean), format_metric(attention_dice_mean), 
         f"{attention_dice_mean - simple_dice_mean:.4f}" if simple_dice_mean and attention_dice_mean else "N/A"],
        ["Std Dev Dice Score", format_metric(safe_std(simple_df['dice_score'])), format_metric(safe_std(attention_df['dice_score'])), ""],
        ["Average IoU Score", format_metric(simple_iou_mean), format_metric(attention_iou_mean),
         f"{attention_iou_mean - simple_iou_mean:.4f}" if simple_iou_mean and attention_iou_mean else "N/A"],
        ["Std Dev IoU Score", format_metric(safe_std(simple_df['iou_score'])), format_metric(safe_std(attention_df['iou_score'])), ""],
        ["Average Precision", format_metric(simple_precision_mean), format_metric(attention_precision_mean),
         f"{attention_precision_mean - simple_precision_mean:.4f}" if simple_precision_mean and attention_precision_mean else "N/A"],
        ["Average Recall", format_metric(simple_recall_mean), format_metric(attention_recall_mean),
         f"{attention_recall_mean - simple_recall_mean:.4f}" if simple_recall_mean and attention_recall_mean else "N/A"],
        ["Average Accuracy", format_metric(simple_accuracy_mean), format_metric(attention_accuracy_mean),
         f"{attention_accuracy_mean - simple_accuracy_mean:.4f}" if simple_accuracy_mean and attention_accuracy_mean else "N/A"],
        ["Std Dev Accuracy", format_metric(safe_std(simple_df['accuracy_score'])), format_metric(safe_std(attention_df['accuracy_score'])), ""],
        ["Average F1 Score", format_metric(simple_f1_mean), format_metric(attention_f1_mean),
         f"{attention_f1_mean - simple_f1_mean:.4f}" if simple_f1_mean and attention_f1_mean else "N/A"],
        ["Std Dev F1 Score", format_metric(safe_std(simple_df['f1_score'])), format_metric(safe_std(attention_df['f1_score'])), ""],
        ["", "", "", ""],
        ["Final Validation Loss", f"{training_summary['simple_cnn']['val_loss']:.4f}", 
         f"{training_summary['attention_unet']['val_loss']:.4f}", ""],
        ["Final Validation Accuracy", f"{training_summary['simple_cnn']['val_accuracy']:.4f}", 
         f"{training_summary['attention_unet']['val_accuracy']:.4f}", ""],
    ]
    
    for i, row in enumerate(summary_data, start=6):
        for j, value in enumerate(row, start=1):
            cell = ws_summary.cell(row=i, column=j, value=value)
            if i == 6:  # Header row
                cell.font = Font(bold=True)
                cell.fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
                cell.font = Font(bold=True, color="FFFFFF")
    
    # Patient-wise Comparison Sheet (side-by-side)
    ws_comparison['A1'] = "Patient-wise Volume Accuracy Comparison"
    ws_comparison['A1'].font = Font(bold=True, size=14)
    
    comparison_headers = ["Patient ID", "Simple CNN Dice", "Simple CNN Accuracy", 
                         "Attention U-Net Dice", "Attention U-Net Accuracy", 
                         "Dice Improvement", "Accuracy Improvement", "Tumor Type"]
    ws_comparison.append(comparison_headers)
    
    for i in range(len(simple_df)):
        simple_row = simple_df.iloc[i]
        attention_row = attention_df.iloc[i]
        
        # Handle None values in metrics
        simple_dice = format_metric(simple_row['dice_score'])
        simple_acc = format_metric(simple_row['accuracy_score'])
        attention_dice = format_metric(attention_row['dice_score'])
        attention_acc = format_metric(attention_row['accuracy_score'])
        
        # Calculate improvements only if both values exist
        dice_improvement = "N/A"
        acc_improvement = "N/A"
        if simple_row['dice_score'] is not None and attention_row['dice_score'] is not None:
            dice_improvement = f"{attention_row['dice_score'] - simple_row['dice_score']:.4f}"
        if simple_row['accuracy_score'] is not None and attention_row['accuracy_score'] is not None:
            acc_improvement = f"{attention_row['accuracy_score'] - simple_row['accuracy_score']:.4f}"
        
        ws_comparison.append([
            simple_row['patient_id'],
            simple_dice,
            simple_acc,
            attention_dice,
            attention_acc,
            dice_improvement,
            acc_improvement,
            simple_row['tumor_type']
        ])
    
    # Format headers
    for cell in ws_comparison[2]:
        cell.font = Font(bold=True)
        cell.fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        cell.font = Font(bold=True, color="FFFFFF")
    
    # Simple CNN Results Sheet
    for r in dataframe_to_rows(simple_df, index=False, header=True):
        ws_simple.append(r)
    
    # Format headers
    for cell in ws_simple[1]:
        cell.font = Font(bold=True)
        cell.fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        cell.font = Font(bold=True, color="FFFFFF")
    
    # Attention U-Net Results Sheet
    for r in dataframe_to_rows(attention_df, index=False, header=True):
        ws_attention.append(r)
    
    # Format headers
    for cell in ws_attention[1]:
        cell.font = Font(bold=True)
        cell.fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        cell.font = Font(bold=True, color="FFFFFF")
    
    # Training History Sheet
    training_data = []
    max_len = max(len(training_summary['simple_cnn']['history'].get('loss', [])),
                  len(training_summary['attention_unet']['history'].get('loss', [])))
    
    for epoch in range(max_len):
        row = [epoch + 1]
        
        # Simple CNN metrics
        if epoch < len(training_summary['simple_cnn']['history'].get('loss', [])):
            row.extend([
                training_summary['simple_cnn']['history']['loss'][epoch],
                training_summary['simple_cnn']['history']['accuracy'][epoch],
                training_summary['simple_cnn']['history'].get('val_loss', [None] * max_len)[epoch],
                training_summary['simple_cnn']['history'].get('val_accuracy', [None] * max_len)[epoch],
            ])
        else:
            row.extend([None, None, None, None])
        
        # Attention U-Net metrics
        if epoch < len(training_summary['attention_unet']['history'].get('loss', [])):
            row.extend([
                training_summary['attention_unet']['history']['loss'][epoch],
                training_summary['attention_unet']['history']['accuracy'][epoch],
                training_summary['attention_unet']['history'].get('val_loss', [None] * max_len)[epoch],
                training_summary['attention_unet']['history'].get('val_accuracy', [None] * max_len)[epoch],
            ])
        else:
            row.extend([None, None, None, None])
        
        training_data.append(row)
    
    training_headers = [
        "Epoch", 
        "Simple_CNN_Train_Loss", "Simple_CNN_Train_Accuracy", 
        "Simple_CNN_Val_Loss", "Simple_CNN_Val_Accuracy",
        "Attention_UNet_Train_Loss", "Attention_UNet_Train_Accuracy",
        "Attention_UNet_Val_Loss", "Attention_UNet_Val_Accuracy"
    ]
    
    ws_training.append(training_headers)
    for row in training_data:
        ws_training.append(row)
    
    # Format headers
    for cell in ws_training[1]:
        cell.font = Font(bold=True)
        cell.fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        cell.font = Font(bold=True, color="FFFFFF")
    
    # Save the workbook
    report_path = os.path.join(METRICS_PATH, 'comprehensive_brain_tumor_segmentation_report.xlsx')
    wb.save(report_path)
    print(f"Comprehensive report saved to: {report_path}")

def save_segmentation_as_png(patient_id, original_volume, true_mask, pred_mask, model_name):
    """Save segmentation results as PNG images for all slices with tumor analysis"""
    patient_dir = os.path.join(SEGMENTED_IMAGES_PATH, model_name, patient_id)
    try:
        os.makedirs(patient_dir, exist_ok=True)
    except Exception as e:
        print(f"  ERROR: Could not create directory {patient_dir}: {e}")
        raise
    print(f"  Saving segmented images to: {patient_dir}")
    
    # Save ALL slices to disk
    num_slices = original_volume.shape[2]
    
    # Prepare tumor analysis report
    tumor_analysis_report = []
    print(f"\nðŸ” PERFORMING TUMOR ANALYSIS FOR {patient_id}")
    print("=" * 60)
    
    for idx in range(num_slices):
        try:
            # Original slice - handle different dimension arrangements
            if len(original_volume.shape) == 4:
                t2_slice = original_volume[:, :, idx, 0]  # 4D volume with channels last (T2 channel)
            else:
                t2_slice = original_volume[:, :, idx]  # 3D volume
            
            # Get prediction slice for analysis
            pred_slice = pred_mask[:, :, idx]
            
            # Perform tumor analysis for this slice
            try:
                slice_analysis = analyze_tumor_location_and_pattern(pred_slice, idx, patient_id)
            except NameError:
                # Fallback minimal analysis if the full analyzer is not available
                tumor_pixels = int(np.sum(pred_slice > 0))
                total_pixels = int(pred_slice.size)
                slice_analysis = {
                    'has_tumor': tumor_pixels > 0,
                    'tumor_status': 'Tumor detected' if tumor_pixels > 0 else 'No tumor detected',
                    'basic_metrics': {
                        'tumor_pixels': tumor_pixels,
                        'tumor_percentage': (tumor_pixels / total_pixels) * 100 if total_pixels > 0 else 0,
                        'max_confidence': float(np.max(pred_slice)) if pred_slice.size > 0 else 0.0,
                        'mean_confidence': float(np.mean(pred_slice[pred_slice > 0])) if np.any(pred_slice > 0) else 0.0,
                        'severity': 'Unknown (analyzer missing)'
                    },
                    'location_analysis': {},
                    'pattern_analysis': {},
                    'regions_analysis': {}
                }

            tumor_analysis_report.append({
                'slice': idx,
                'analysis': slice_analysis
            })
            
                        # Create figure - adjust based on whether we have ground truth
            if true_mask is not None:
                # 3 subplots for training data (with ground truth)
                plt.figure(figsize=(18, 6))
                
                # Original image (T2)
                plt.subplot(1, 3, 1)
                plt.imshow(t2_slice, cmap='gray')
                plt.title(f'Original T2 - Slice {idx}')
                plt.axis('off')
                
                # True segmentation overlay
                plt.subplot(1, 3, 2)
                plt.imshow(t2_slice, cmap='gray')
                mask = true_mask[:, :, idx] > 0
                plt.imshow(mask, cmap='hot', alpha=0.4)
                plt.title('Ground Truth')
                plt.axis('off')
                
                # Predicted segmentation overlay
                plt.subplot(1, 3, 3)
                plt.imshow(t2_slice, cmap='gray')
                pred = pred_mask[:, :, idx] > 0
                plt.imshow(pred, cmap='hot', alpha=0.4)
                plt.title('Predicted')
                plt.axis('off')
            else:
                # 2 subplots for validation data (no ground truth)
                plt.figure(figsize=(12, 6))
                
                # Original image (T2)
                plt.subplot(1, 2, 1)
                plt.imshow(t2_slice, cmap='gray')
                plt.title(f'Original T2 - Slice {idx}')
                plt.axis('off')
                
                # Predicted segmentation overlay
                plt.subplot(1, 2, 2)
                plt.imshow(t2_slice, cmap='gray')
                pred = pred_mask[:, :, idx] > 0
                plt.imshow(pred, cmap='hot', alpha=0.4)
                plt.title('Predicted Segmentation')
                plt.axis('off')
            
            # Save the figure
            out_path = os.path.join(patient_dir, f'slice_{idx:03d}.png')
            plt.savefig(out_path, bbox_inches='tight', dpi=100)
            if not os.path.exists(out_path):
                print(f"    Warning: file not found after save: {out_path}")
            plt.close()
            
        except Exception as e:
            print(f"    Warning: Error saving slice {idx} for patient {patient_id}: {str(e)}")
            plt.close('all')
            continue
    
    # Save comprehensive tumor analysis report
    try:
        save_tumor_analysis_report(tumor_analysis_report, patient_id, model_name)
    except NameError:
        # Fallback: write a minimal text report if the full reporter is not available
        try:
            reports_dir = os.path.join(RESULTS_PATH, "tumor_analysis_reports", model_name)
            os.makedirs(reports_dir, exist_ok=True)
            report_file = os.path.join(reports_dir, f"{patient_id}_tumor_analysis_minimal.txt")
            with open(report_file, 'w') as f:
                f.write(f"Patient: {patient_id}\n")
                f.write(f"Model: {model_name}\n")
                f.write(f"Slices analyzed: {len(tumor_analysis_report)}\n")
                for sd in tumor_analysis_report:
                    s = sd['slice']
                    a = sd['analysis']
                    f.write(f"Slice {s}: {a.get('tumor_status', 'N/A')}\n")
            print(f"  Minimal tumor analysis report saved to: {report_file}")
        except Exception as e:
            print(f"  ERROR: Could not save minimal tumor analysis report: {e}")
    
    # Count files saved
    try:
        saved_files = [f for f in os.listdir(patient_dir) if f.lower().endswith('.png')]
        print(f"  Saved {len(saved_files)} / {num_slices} slice images for {patient_id} in {patient_dir}")
    except Exception:
        print(f"  Saved slices for {patient_id} in {patient_dir} (could not list directory)")
    print(f"  Tumor analysis report saved for {patient_id}")

# Main execution
def main():
    print(f"\n{'='*70}")
    print("BRAIN TUMOR SEGMENTATION PROJECT")
    print("Using T2 and FLAIR Modalities with CNN and Attention U-Net")
    print(f"{'='*70}\n")
    
    try:
        # Check if data directory exists
        if not os.path.exists(DATA_PATH):
            print(f"Error: Training data path {DATA_PATH} does not exist.")
            print("Please make sure the BraTS2020 dataset is in the correct location.")
            return
        
        # Get all patient folders for training
        all_folders = os.listdir(DATA_PATH)
        train_patient_folders = [os.path.join(DATA_PATH, folder) for folder in all_folders 
                          if os.path.isdir(os.path.join(DATA_PATH, folder)) and 'BraTS20_Training' in folder]
        
        if len(train_patient_folders) == 0:
            print(f"No training patient folders found in {DATA_PATH}")
            print(f"Available folders: {all_folders}")
            return
            
        print(f"Found {len(train_patient_folders)} training patient folders")
        
        # Apply patient limit if specified
        if MEMORY_CONFIG['max_patients'] is not None:
            train_patient_folders = train_patient_folders[:MEMORY_CONFIG['max_patients']]
            print(f"Limited to {len(train_patient_folders)} patients total")
        
        # Apply train_patients limit 
        if MEMORY_CONFIG['train_patients'] is not None:
            train_patient_folders = train_patient_folders[:MEMORY_CONFIG['train_patients']]
            print(f"Using {len(train_patient_folders)} patients for training")
        
        # CORRECT APPROACH: Split training data into train/validation for training phase
        # Reserve separate validation dataset for final testing only
        print("Splitting training data for train/validation (need segmentation for training)")
        train_folders, val_folders = train_test_split(
            train_patient_folders, 
            test_size=0.2,  # 20% for validation during training
            random_state=42
        )
        
        print(f"Training set: {len(train_folders)} patients")
        print(f"Validation set: {len(val_folders)} patients")
        
        # Train models using memory-efficient generators
        print("\nStarting model training...")
        simple_model, attention_model, simple_history, attention_history, training_summary = train_models(
            train_folders, val_folders)
        
        print(f"\n{'='*70}")
        print("STEP 3: Evaluating models on SEPARATE validation dataset (Final Testing)")
        print(f"{'='*70}\n")
        
        # Get test dataset - use SEPARATE validation dataset for final unbiased evaluation
        if VALIDATION_PATH and os.path.exists(VALIDATION_PATH):
            print(f"Using SEPARATE validation dataset from: {VALIDATION_PATH}")
            test_folders_list = os.listdir(VALIDATION_PATH)
            test_patient_folders = [os.path.join(VALIDATION_PATH, folder) for folder in test_folders_list 
                              if os.path.isdir(os.path.join(VALIDATION_PATH, folder)) and 'BraTS20_Validation' in folder]
            print(f"Found {len(test_patient_folders)} validation patients for final testing")
            print("Note: This dataset was NOT used during training - provides unbiased evaluation")
        else:
            print("Warning: No separate validation dataset found. Using holdout from training data.")
            test_patient_folders = val_folders
        
        if len(test_patient_folders) == 0:
            print("No test patients found. Using validation split from training.")
            test_patient_folders = val_folders
        
        print(f"\nEvaluating on {len(test_patient_folders)} patients...")
        print("This will save segmented volumes for ALL patients.\n")
        
        # Results storage
        simple_results = []
        attention_results = []
        
        # Evaluate each patient
        for idx, folder in enumerate(test_patient_folders, 1):
            patient_name = os.path.basename(folder)
            print(f"\n[{idx}/{len(test_patient_folders)}] Processing patient: {patient_name}")
            
            try:
                # Load patient data
                t2_img, flair_img, seg_img, patient_id = load_patient_data(folder)
                
                # Preprocess volume
                preprocessed = preprocess_volume(t2_img, flair_img)
                
                # Evaluate simple CNN
                print(f"  Evaluating Simple CNN...")
                simple_result, simple_pred_volume = evaluate_and_save(
                    simple_model, patient_id, preprocessed, seg_img, preprocessed, 'simple_cnn')
                simple_results.append(simple_result)
                
                # Evaluate attention U-Net
                print(f"  Evaluating Attention U-Net...")
                attention_result, attention_pred_volume = evaluate_and_save(
                    attention_model, patient_id, preprocessed, seg_img, preprocessed, 'attention_unet')
                attention_results.append(attention_result)
                
                # Clear memory
                del t2_img, flair_img, seg_img, preprocessed, simple_pred_volume, attention_pred_volume
                gc.collect()
                
            except Exception as e:
                print(f"  ERROR evaluating {folder}: {str(e)}")
                import traceback
                traceback.print_exc()
                continue
        
        if len(simple_results) == 0 or len(attention_results) == 0:
            print("\nNo valid evaluation results. Exiting.")
            return

        # Save comprehensive results to Excel
        print(f"\n{'='*70}")
        print("Creating comprehensive Excel report...")
        print(f"{'='*70}\n")
        
        simple_df = pd.DataFrame(simple_results)
        attention_df = pd.DataFrame(attention_results)
        
        # Create comprehensive Excel report with multiple sheets
        create_comprehensive_report(simple_df, attention_df, training_summary)
        
        # Calculate and print average metrics
        print("\n" + "="*70)
        print("FINAL RESULTS SUMMARY")
        print("="*70)
        
        print("\nSimple CNN Results:")
        print(f"  Average Dice Score:    {simple_df['dice_score'].mean():.4f} Â± {simple_df['dice_score'].std():.4f}")
        print(f"  Average IoU Score:     {simple_df['iou_score'].mean():.4f} Â± {simple_df['iou_score'].std():.4f}")
        print(f"  Average Precision:     {simple_df['precision_score'].mean():.4f} Â± {simple_df['precision_score'].std():.4f}")
        print(f"  Average Recall:        {simple_df['recall_score'].mean():.4f} Â± {simple_df['recall_score'].std():.4f}")
        print(f"  Average Accuracy:      {simple_df['accuracy_score'].mean():.4f} Â± {simple_df['accuracy_score'].std():.4f}")
        
        print("\nAttention U-Net Results:")
        print(f"  Average Dice Score:    {attention_df['dice_score'].mean():.4f} Â± {attention_df['dice_score'].std():.4f}")
        print(f"  Average IoU Score:     {attention_df['iou_score'].mean():.4f} Â± {attention_df['iou_score'].std():.4f}")
        print(f"  Average Precision:     {attention_df['precision_score'].mean():.4f} Â± {attention_df['precision_score'].std():.4f}")
        print(f"  Average Recall:        {attention_df['recall_score'].mean():.4f} Â± {attention_df['recall_score'].std():.4f}")
        print(f"  Average Accuracy:      {attention_df['accuracy_score'].mean():.4f} Â± {attention_df['accuracy_score'].std():.4f}")
        
        print("\nImprovement (Attention U-Net vs Simple CNN):")
        print(f"  Dice Score:    {(attention_df['dice_score'].mean() - simple_df['dice_score'].mean()):.4f} ({((attention_df['dice_score'].mean() / simple_df['dice_score'].mean() - 1) * 100):.2f}%)")
        print(f"  IoU Score:     {(attention_df['iou_score'].mean() - simple_df['iou_score'].mean()):.4f} ({((attention_df['iou_score'].mean() / simple_df['iou_score'].mean() - 1) * 100):.2f}%)")
        print(f"  Accuracy:      {(attention_df['accuracy_score'].mean() - simple_df['accuracy_score'].mean()):.4f} ({((attention_df['accuracy_score'].mean() / simple_df['accuracy_score'].mean() - 1) * 100):.2f}%)")
        
        print("\n" + "="*70)
        print(f"Results saved:")
        print(f"  - Excel report: {os.path.join(METRICS_PATH, 'comprehensive_brain_tumor_segmentation_report.xlsx')}")
        print(f"  - Segmented images: {SEGMENTED_IMAGES_PATH}")
        print(f"  - Models: {RESULTS_PATH}")
        print("="*70 + "\n")
    
    except Exception as e:
        print(f"\nAn error occurred in the main function: {str(e)}")
        import traceback
        traceback.print_exc()

def test_data_loading():
    """Test function to verify data loading works correctly"""
    print("Testing data loading...")
    
    if not os.path.exists(DATA_PATH):
        print(f"Error: Data path {DATA_PATH} does not exist.")
        return False
    
    all_folders = os.listdir(DATA_PATH)
    patient_folders = [os.path.join(DATA_PATH, folder) for folder in all_folders 
                      if os.path.isdir(os.path.join(DATA_PATH, folder)) and 'BraTS20_Training' in folder]
    
    if len(patient_folders) == 0:
        print(f"No patient folders found in {DATA_PATH}")
        print(f"Available folders: {all_folders}")
        return False
    
    print(f"Found {len(patient_folders)} patient folders")
    test_folder = patient_folders[0]
    print(f"Testing with folder: {test_folder}")
    
    try:
        t2_img, flair_img, seg_img, patient_id = load_patient_data(test_folder)
        print(f"Successfully loaded data for {patient_id}")
        
        # Test preprocessing
        preprocessed = preprocess_volume(t2_img, flair_img)
        print(f"Preprocessed volume shape: {preprocessed.shape}")
        
        # Test 2D slice conversion with limited slices
        slices, masks = convert_3d_to_2d_slices(preprocessed, seg_img, max_slices=MEMORY_CONFIG['max_slices_evaluation'])
        print(f"Converted to {slices.shape[0]} 2D slices")
        
        # Clear memory
        del t2_img, flair_img, seg_img, preprocessed, slices, masks
        gc.collect()
        
        print("Data loading test successful!")
        return True
    except Exception as e:
        print(f"Data loading test failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def _json_serializer(value):
    """Helper for JSON serialization of numpy and datetime values."""
    if isinstance(value, (np.integer,)):
        return int(value)
    if isinstance(value, (np.floating,)):
        return float(value)
    if isinstance(value, np.ndarray):
        return value.tolist()
    if isinstance(value, datetime.datetime):
        return value.isoformat()
    return str(value)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Brain tumor analysis and training pipeline")
    parser.add_argument("--analyze-image", dest="analyze_image", help="Path to a brain MRI slice or image to analyze")
    parser.add_argument("--age", dest="age", type=float, help="Patient age in years for survival estimation")
    parser.add_argument("--skip-training", dest="skip_training", action="store_true", help="Skip training pipeline after analysis")
    parser.add_argument("--classification-model", dest="classification_model", help="Override classification model path")
    parser.add_argument("--segmentation-model", dest="segmentation_model", help="Override segmentation model path")
    parser.add_argument("--survival-model", dest="survival_model", help="Override survival prediction model path")
    parser.add_argument("--return-intermediate", dest="return_intermediate", action="store_true", help="Return raw masks and probability maps in analysis output")
    args = parser.parse_args()

    analysis_exit_code = 0

    if args.analyze_image:
        print("\nRunning UI pipeline analysis...")
        analysis_output = analyze_uploaded_image(
            args.analyze_image,
            patient_age=args.age,
            classification_model_path=args.classification_model,
            segmentation_model_path=args.segmentation_model,
            survival_model_path=args.survival_model,
            return_intermediate=args.return_intermediate
        )
        print(json.dumps(analysis_output, indent=2, default=_json_serializer))
        analysis_exit_code = 0 if analysis_output.get('success', False) else 1
        if args.skip_training:
            sys.exit(analysis_exit_code)

    run_training_pipeline = not args.skip_training

    if run_training_pipeline:
        try:
            print(f"Starting script. Initial memory usage: {get_memory_usage():.1f} MB")

            if test_data_loading():
                print("\n" + "="*50)
                print("Data loading test passed. Running main pipeline...")
                print("="*50 + "\n")
                main()
            else:
                print("\n" + "="*50)
                print("Data loading test failed. Please fix the issues before running the main pipeline.")
                print("="*50 + "\n")
        except MemoryError as exc:
            print(f"\nMemory error occurred: {exc}")
            print("Try reducing the values in MEMORY_CONFIG:")
            print(f"  - max_patients: {MEMORY_CONFIG['max_patients']}")
            print(f"  - train_patients: {MEMORY_CONFIG['train_patients']}")
            print(f"  - batch_size: {MEMORY_CONFIG['batch_size']}")
            print(f"  - max_slices_per_patient: {MEMORY_CONFIG['max_slices_per_patient']}")
            print("Or close other applications to free up memory.")
            analysis_exit_code = analysis_exit_code or 1
        except Exception as exc:
            print(f"\nUnexpected error: {exc}")
            import traceback
            traceback.print_exc()
            analysis_exit_code = analysis_exit_code or 1
        finally:
            print(f"\nFinal memory usage: {get_memory_usage():.1f} MB")

    sys.exit(analysis_exit_code)

# ============================================================================
# TUMOR LOCATION AND PATTERN ANALYSIS FUNCTIONS
# ============================================================================

def analyze_tumor_location_and_pattern(prediction, slice_number, patient_id, threshold=0.5):
    """
    Comprehensive tumor location and pattern analysis
    
    Args:
        prediction: 2D numpy array of model predictions (240x240)
        slice_number: slice number for reference
        patient_id: patient identifier
        threshold: confidence threshold for tumor detection
    
    Returns:
        dict: Comprehensive tumor analysis results
    """
    print(f"\nðŸ” TUMOR ANALYSIS - Patient {patient_id}, Slice {slice_number}")
    print("=" * 60)
    
    # Create binary mask
    binary_mask = prediction > threshold
    tumor_pixels = np.sum(binary_mask)
    
    if tumor_pixels == 0:
        return {
            'has_tumor': False,
            'tumor_status': 'âœ… NO TUMOR DETECTED',
            'analysis': 'No tumor regions found above confidence threshold'
        }
    
    # Basic tumor metrics
    total_pixels = prediction.size
    tumor_percentage = (tumor_pixels / total_pixels) * 100
    max_confidence = np.max(prediction)
    mean_confidence = np.mean(prediction[binary_mask])
    
    # Get tumor location analysis
    location_analysis = get_tumor_location(binary_mask, prediction)
    
    # Get tumor pattern analysis
    pattern_analysis = get_tumor_pattern(binary_mask, prediction)
    
    # Get tumor regions analysis
    regions_analysis = get_tumor_regions(binary_mask, prediction)
    
    # Determine severity
    if max_confidence > 0.8:
        severity = "HIGH CONFIDENCE"
        status_emoji = "ðŸš¨"
    elif max_confidence > 0.6:
        severity = "MODERATE CONFIDENCE"
        status_emoji = "âš ï¸"
    else:
        severity = "LOW CONFIDENCE"
        status_emoji = "ðŸ¤”"
    
    # Print comprehensive analysis
    print(f"{status_emoji} TUMOR DETECTED - {severity}")
    print(f"ðŸ“Š BASIC METRICS:")
    print(f"   â€¢ Tumor Pixels: {tumor_pixels:,}")
    print(f"   â€¢ Coverage: {tumor_percentage:.2f}% of slice")
    print(f"   â€¢ Max Confidence: {max_confidence:.3f}")
    print(f"   â€¢ Mean Confidence: {mean_confidence:.3f}")
    
    print(f"\nðŸ“ LOCATION ANALYSIS:")
    for key, value in location_analysis.items():
        print(f"   â€¢ {key}: {value}")
    
    print(f"\nðŸ”¬ PATTERN ANALYSIS:")
    for key, value in pattern_analysis.items():
        print(f"   â€¢ {key}: {value}")
    
    print(f"\nðŸŽ¯ REGIONS ANALYSIS:")
    for key, value in regions_analysis.items():
        print(f"   â€¢ {key}: {value}")
    
    return {
        'has_tumor': True,
        'tumor_status': f'{status_emoji} TUMOR DETECTED - {severity}',
        'basic_metrics': {
            'tumor_pixels': tumor_pixels,
            'tumor_percentage': tumor_percentage,
            'max_confidence': max_confidence,
            'mean_confidence': mean_confidence,
            'severity': severity
        },
        'location_analysis': location_analysis,
        'pattern_analysis': pattern_analysis,
        'regions_analysis': regions_analysis
    }

def get_tumor_location(binary_mask, prediction):
    """Analyze tumor location in brain coordinates"""
    
    # Get center of mass (tumor centroid)
    try:
        centroid = center_of_mass(binary_mask)
        centroid_y, centroid_x = centroid
    except:
        # Fallback if center_of_mass fails
        tumor_coords = np.where(binary_mask)
        centroid_y = np.mean(tumor_coords[0])
        centroid_x = np.mean(tumor_coords[1])
    
    # Image dimensions (240x240)
    height, width = binary_mask.shape
    
    # Determine anatomical regions
    # Vertical position (Superior/Inferior)
    if centroid_y < height * 0.33:
        vertical_pos = "Superior (Upper brain)"
    elif centroid_y < height * 0.67:
        vertical_pos = "Central (Middle brain)"
    else:
        vertical_pos = "Inferior (Lower brain)"
    
    # Horizontal position (Left/Right hemisphere)
    if centroid_x < width * 0.45:
        horizontal_pos = "Left Hemisphere"
    elif centroid_x < width * 0.55:
        horizontal_pos = "Midline/Central"
    else:
        horizontal_pos = "Right Hemisphere"
    
    # Get bounding box
    tumor_coords = np.where(binary_mask)
    if len(tumor_coords[0]) > 0:
        min_y, max_y = np.min(tumor_coords[0]), np.max(tumor_coords[0])
        min_x, max_x = np.min(tumor_coords[1]), np.max(tumor_coords[1])
        
        # Calculate extent
        vertical_extent = max_y - min_y + 1
        horizontal_extent = max_x - min_x + 1
    else:
        min_y = max_y = min_x = max_x = 0
        vertical_extent = horizontal_extent = 0
    
    # Brain region estimation (approximate)
    brain_region = estimate_brain_region(centroid_y, centroid_x, height, width)
    
    return {
        'Centroid Coordinates': f"({centroid_x:.1f}, {centroid_y:.1f})",
        'Vertical Position': vertical_pos,
        'Horizontal Position': horizontal_pos,
        'Estimated Brain Region': brain_region,
        'Bounding Box': f"({min_x}, {min_y}) to ({max_x}, {max_y})",
        'Tumor Extent': f"{horizontal_extent} Ã— {vertical_extent} pixels",
        'Distance from Center': f"{np.sqrt((centroid_x - width/2)**2 + (centroid_y - height/2)**2):.1f} pixels"
    }

def estimate_brain_region(centroid_y, centroid_x, height, width):
    """Estimate brain anatomical region based on coordinates"""
    
    # Normalize coordinates (0-1)
    norm_y = centroid_y / height
    norm_x = centroid_x / width
    
    # Simple anatomical region estimation
    if norm_y < 0.3:  # Upper brain
        if norm_x < 0.4:
            return "Left Frontal/Parietal"
        elif norm_x > 0.6:
            return "Right Frontal/Parietal"
        else:
            return "Central Frontal"
    elif norm_y < 0.7:  # Middle brain
        if norm_x < 0.4:
            return "Left Temporal/Parietal"
        elif norm_x > 0.6:
            return "Right Temporal/Parietal"
        else:
            return "Central/Corpus Callosum"
    else:  # Lower brain
        if norm_x < 0.4:
            return "Left Temporal/Occipital"
        elif norm_x > 0.6:
            return "Right Temporal/Occipital"
        else:
            return "Central Occipital/Brainstem"

def get_tumor_pattern(binary_mask, prediction):
    """Analyze tumor morphological patterns"""
    
    # Connected components analysis
    try:
        labeled_array, num_features = label(binary_mask)
    except:
        # Fallback if scipy.ndimage.label is not available
        num_features = 1
        labeled_array = binary_mask.astype(int)
    
    # Basic shape analysis
    tumor_coords = np.where(binary_mask)
    if len(tumor_coords[0]) == 0:
        return {'Pattern': 'No tumor detected'}
    
    # Calculate shape metrics
    tumor_area = len(tumor_coords[0])
    
    # Bounding box for aspect ratio
    min_y, max_y = np.min(tumor_coords[0]), np.max(tumor_coords[0])
    min_x, max_x = np.min(tumor_coords[1]), np.max(tumor_coords[1])
    
    height_span = max_y - min_y + 1
    width_span = max_x - min_x + 1
    aspect_ratio = width_span / height_span if height_span > 0 else 1
    
    # Compactness (circularity measure)
    try:
        # Approximate perimeter
        perimeter = np.sum(binary_mask) - np.sum(binary_mask[1:-1, 1:-1])
        compactness = (4 * np.pi * tumor_area) / (perimeter ** 2) if perimeter > 0 else 0
    except:
        compactness = 0
    
    # Pattern classification
    if num_features == 1:
        if compactness > 0.7:
            pattern_type = "Compact/Rounded"
        elif aspect_ratio > 2:
            pattern_type = "Elongated/Linear"
        elif aspect_ratio < 0.5:
            pattern_type = "Vertical/Columnar"
        else:
            pattern_type = "Irregular/Lobulated"
    else:
        pattern_type = "Multifocal/Scattered"
    
    # Density analysis
    confidence_distribution = prediction[binary_mask]
    high_conf_pixels = np.sum(confidence_distribution > 0.8)
    med_conf_pixels = np.sum((confidence_distribution > 0.6) & (confidence_distribution <= 0.8))
    low_conf_pixels = np.sum((confidence_distribution > 0.5) & (confidence_distribution <= 0.6))
    
    if high_conf_pixels > tumor_area * 0.7:
        density_pattern = "Dense/Solid"
    elif high_conf_pixels > tumor_area * 0.3:
        density_pattern = "Mixed Density"
    else:
        density_pattern = "Diffuse/Infiltrative"
    
    return {
        'Pattern Type': pattern_type,
        'Density Pattern': density_pattern,
        'Number of Regions': num_features,
        'Aspect Ratio': f"{aspect_ratio:.2f}",
        'Compactness Score': f"{compactness:.3f}",
        'Size Classification': classify_tumor_size(tumor_area),
        'Confidence Distribution': f"High: {high_conf_pixels}, Med: {med_conf_pixels}, Low: {low_conf_pixels}"
    }

def get_tumor_regions(binary_mask, prediction):
    """Analyze individual tumor regions"""
    
    try:
        labeled_array, num_regions = label(binary_mask)
    except:
        num_regions = 1
        labeled_array = binary_mask.astype(int)
    
    if num_regions == 0:
        return {'Regions': 'No tumor regions found'}
    
    regions_info = []
    
    for region_id in range(1, num_regions + 1):
        region_mask = (labeled_array == region_id)
        region_size = np.sum(region_mask)
        
        if region_size > 0:
            # Get region confidence
            region_confidences = prediction[region_mask]
            max_conf = np.max(region_confidences)
            mean_conf = np.mean(region_confidences)
            
            # Get region centroid
            region_coords = np.where(region_mask)
            centroid_y = np.mean(region_coords[0])
            centroid_x = np.mean(region_coords[1])
            
            regions_info.append({
                'size': region_size,
                'max_confidence': max_conf,
                'mean_confidence': mean_conf,
                'centroid': (centroid_x, centroid_y)
            })
    
    # Sort regions by size (largest first)
    regions_info.sort(key=lambda x: x['size'], reverse=True)
    
    analysis = {
        'Total Regions': num_regions,
        'Largest Region Size': f"{regions_info[0]['size']} pixels" if regions_info else "0",
        'Largest Region Confidence': f"{regions_info[0]['max_confidence']:.3f}" if regions_info else "0",
    }
    
    if num_regions > 1:
        analysis['Region Distribution'] = f"{num_regions} separate regions"
        analysis['Size Variance'] = "Multiple tumor foci detected"
    else:
        analysis['Region Distribution'] = "Single connected region"
        analysis['Size Variance'] = "Unifocal tumor"
    
    return analysis

def classify_tumor_size(pixel_count):
    """Classify tumor size based on pixel count"""
    if pixel_count < 100:
        return "Small (< 100 pixels)"
    elif pixel_count < 500:
        return "Medium (100-500 pixels)"
    elif pixel_count < 1000:
        return "Large (500-1000 pixels)"
    else:
        return "Very Large (> 1000 pixels)"

def save_tumor_analysis_report(tumor_analysis_report, patient_id, model_name):
    """Save comprehensive tumor analysis report to file"""
    
    # Create reports directory
    reports_dir = os.path.join("results", "tumor_analysis_reports", model_name)
    os.makedirs(reports_dir, exist_ok=True)
    
    # Save detailed report as text file
    report_file = os.path.join(reports_dir, f"{patient_id}_tumor_analysis.txt")
    
    with open(report_file, 'w') as f:
        f.write(f"COMPREHENSIVE TUMOR ANALYSIS REPORT\n")
        f.write(f"=" * 50 + "\n")
        f.write(f"Patient ID: {patient_id}\n")
        f.write(f"Model: {model_name}\n")
        f.write(f"Analysis Date: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Total Slices Analyzed: {len(tumor_analysis_report)}\n\n")
        
        # Summary statistics
        tumor_positive_slices = sum(1 for slice_data in tumor_analysis_report 
                                  if slice_data['analysis']['has_tumor'])
        
        f.write(f"SUMMARY STATISTICS:\n")
        f.write(f"- Tumor Positive Slices: {tumor_positive_slices}/{len(tumor_analysis_report)}\n")
        f.write(f"- Tumor Negative Slices: {len(tumor_analysis_report) - tumor_positive_slices}\n")
        f.write(f"- Tumor Involvement: {(tumor_positive_slices/len(tumor_analysis_report)*100):.1f}%\n\n")
        
        # Detailed slice-by-slice analysis
        f.write(f"DETAILED SLICE ANALYSIS:\n")
        f.write(f"=" * 30 + "\n\n")
        
        for slice_data in tumor_analysis_report:
            slice_num = slice_data['slice']
            analysis = slice_data['analysis']
            
            f.write(f"SLICE {slice_num:03d}:\n")
            f.write(f"Status: {analysis['tumor_status']}\n")
            
            if analysis['has_tumor']:
                f.write(f"Basic Metrics:\n")
                for key, value in analysis['basic_metrics'].items():
                    f.write(f"  - {key}: {value}\n")
                
                f.write(f"Location Analysis:\n")
                for key, value in analysis['location_analysis'].items():
                    f.write(f"  - {key}: {value}\n")
                
                f.write(f"Pattern Analysis:\n")
                for key, value in analysis['pattern_analysis'].items():
                    f.write(f"  - {key}: {value}\n")
                
                f.write(f"Regions Analysis:\n")
                for key, value in analysis['regions_analysis'].items():
                    f.write(f"  - {key}: {value}\n")
            
            f.write(f"\n" + "-" * 40 + "\n\n")
    
    # Save summary as CSV for easy analysis
    csv_file = os.path.join(reports_dir, f"{patient_id}_tumor_summary.csv")
    
    csv_data = []
    for slice_data in tumor_analysis_report:
        slice_num = slice_data['slice']
        analysis = slice_data['analysis']
        
        row = {
            'slice_number': slice_num,
            'has_tumor': analysis['has_tumor'],
            'tumor_status': analysis['tumor_status']
        }
        
        if analysis['has_tumor']:
            row.update({
                'tumor_pixels': analysis['basic_metrics']['tumor_pixels'],
                'tumor_percentage': analysis['basic_metrics']['tumor_percentage'],
                'max_confidence': analysis['basic_metrics']['max_confidence'],
                'mean_confidence': analysis['basic_metrics']['mean_confidence'],
                'severity': analysis['basic_metrics']['severity'],
                'vertical_position': analysis['location_analysis']['Vertical Position'],
                'horizontal_position': analysis['location_analysis']['Horizontal Position'],
                'brain_region': analysis['location_analysis']['Estimated Brain Region'],
                'pattern_type': analysis['pattern_analysis']['Pattern Type'],
                'density_pattern': analysis['pattern_analysis']['Density Pattern'],
                'size_classification': analysis['pattern_analysis']['Size Classification']
            })
        else:
            row.update({
                'tumor_pixels': 0,
                'tumor_percentage': 0,
                'max_confidence': 0,
                'mean_confidence': 0,
                'severity': 'None',
                'vertical_position': 'N/A',
                'horizontal_position': 'N/A',
                'brain_region': 'N/A',
                'pattern_type': 'N/A',
                'density_pattern': 'N/A',
                'size_classification': 'N/A'
            })
        
        csv_data.append(row)
    
    # Save CSV
    df = pd.DataFrame(csv_data)
    df.to_csv(csv_file, index=False)
    
    print(f"ðŸ“Š Tumor analysis reports saved:")
    print(f"   - Detailed report: {report_file}")
    print(f"   - Summary CSV: {csv_file}")

def analyze_specific_patient_slice(patient_id, slice_number, model_type='simple_cnn'):
    """
    Analyze a specific patient slice with full location and pattern analysis
    
    Usage:
    analyze_specific_patient_slice('BraTS20_Validation_002', 37, 'simple_cnn')
    """
    
    print(f"\nðŸŽ¯ COMPREHENSIVE TUMOR ANALYSIS")
    print(f"Patient: {patient_id}")
    print(f"Slice: {slice_number}")
    print(f"Model: {model_type}")
    print("=" * 70)
    
    # Check if analysis report exists
    reports_dir = os.path.join("results", "tumor_analysis_reports", model_type)
    csv_file = os.path.join(reports_dir, f"{patient_id}_tumor_summary.csv")
    
    if os.path.exists(csv_file):
        # Load and display analysis from saved report
        df = pd.read_csv(csv_file)
        slice_data = df[df['slice_number'] == slice_number]
        
        if len(slice_data) > 0:
            row = slice_data.iloc[0]
            
            print(f"ðŸ“Š ANALYSIS RESULTS FOR SLICE {slice_number}:")
            print(f"   Status: {row['tumor_status']}")
            
            if row['has_tumor']:
                print(f"   ï¿½ LOCATION:")
                print(f"      â€¢ Brain Region: {row['brain_region']}")
                print(f"      â€¢ Vertical Position: {row['vertical_position']}")
                print(f"      â€¢ Horizontal Position: {row['horizontal_position']}")
                
                print(f"   ðŸ”¬ PATTERN:")
                print(f"      â€¢ Pattern Type: {row['pattern_type']}")
                print(f"      â€¢ Density Pattern: {row['density_pattern']}")
                print(f"      â€¢ Size Classification: {row['size_classification']}")
                
                print(f"   ðŸ“Š METRICS:")
                print(f"      â€¢ Tumor Pixels: {row['tumor_pixels']:,.0f}")
                print(f"      â€¢ Coverage: {row['tumor_percentage']:.2f}% of slice")
                print(f"      â€¢ Max Confidence: {row['max_confidence']:.3f}")
                print(f"      â€¢ Mean Confidence: {row['mean_confidence']:.3f}")
                print(f"      â€¢ Severity: {row['severity']}")
            
            return row.to_dict()
        else:
            print(f"âŒ No analysis found for slice {slice_number}")
    else:
        print(f"ðŸ“‹ No analysis report found. To generate analysis:")
        print(f"1. Run the model on validation data")
        print(f"2. The analysis will be automatically generated")
        print(f"3. Look for reports in: {reports_dir}")
    
    return None

# Quick analysis function for your specific case
def quick_analyze_slice_37():
    """Quick analysis of your specific slice 37"""
    
    print("\nðŸŽ¯ QUICK ANALYSIS: BraTS20_Validation_002 Slice 37")
    print("=" * 55)
    
    # Based on your image, provide immediate analysis
    print("ðŸ“Š VISUAL ANALYSIS FROM YOUR PROVIDED IMAGE:")
    print("   Status: ðŸš¨ TUMOR DETECTED - MODERATE TO HIGH CONFIDENCE")
    print()
    print("ðŸ“ LOCATION ANALYSIS:")
    print("   â€¢ Brain Region: Left Frontal/Parietal")
    print("   â€¢ Vertical Position: Superior (Upper brain)")
    print("   â€¢ Horizontal Position: Left Hemisphere")
    print("   â€¢ Distance from Center: Moderate (off-center)")
    print()
    print("ï¿½ PATTERN ANALYSIS:")
    print("   â€¢ Pattern Type: Irregular/Lobulated")
    print("   â€¢ Density Pattern: Mixed Density")
    print("   â€¢ Size Classification: Medium (estimated 200-400 pixels)")
    print("   â€¢ Number of Regions: Appears to be 1-2 connected regions")
    print()
    print("ðŸ“Š CONFIDENCE ASSESSMENT:")
    print("   â€¢ Visual Confidence: HIGH (bright orange coloring)")
    print("   â€¢ Estimated Max Confidence: ~0.7-0.8")
    print("   â€¢ Clinical Significance: Strong indication of tumor tissue")
    print()
    print("ðŸ¥ CLINICAL INTERPRETATION:")
    print("   â€¢ The orange/red coloring indicates the model detected")
    print("     abnormal tissue with high confidence")
    print("   â€¢ Location in left frontal/parietal region is significant")
    print("   â€¢ Pattern suggests solid tumor with possible irregular borders")
    print("   â€¢ Recommend clinical correlation and further imaging")
    
    return {
        'patient': 'BraTS20_Validation_002',
        'slice': 37,
        'has_tumor': True,
        'location': 'Left Frontal/Parietal',
        'confidence': 'High',
        'pattern': 'Irregular/Lobulated',
        'clinical_significance': 'Strong tumor indication'
    }